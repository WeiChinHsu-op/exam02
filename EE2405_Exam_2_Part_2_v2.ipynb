{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "EE2405_Exam_2_Part_2_v2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/WeiChinHsu-op/exam02/blob/master/EE2405_Exam_2_Part_2_v2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DI1ebUOX16FD",
        "colab_type": "text"
      },
      "source": [
        "# EE2405 Embedded System Lab Exam #2 Part 2\n",
        "\n",
        "**Please click on \"Open in playground\" at the upper-left corner to create a copy for you.**\n",
        "\n",
        "---\n",
        "\n",
        "**Please fill in correct statements in the right of the codes to finish the scripts.**  \n",
        "Data sample is generated with a quadratic function and we will train a regression model to fit the data.  \n",
        "And we convert and interpret the trained model with a Tensorflow lite APIs.\n",
        "\n",
        "You can run the script again after you fill all the blank to check the outputs.\n",
        "\n",
        "---\n",
        "\n",
        "The Method to Download the Jupyter Notebook:  \n",
        "File > Download .ipynb"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HC3FqFF1zRJW",
        "colab_type": "text"
      },
      "source": [
        "## Import dependencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zhRpD2SsyQrm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# TensorFlow is an open source machine learning library\n",
        "import tensorflow as tf\n",
        "# Numpy is a math library\n",
        "import numpy as np\n",
        "# Matplotlib is a graphing library\n",
        "import matplotlib.pyplot as plt\n",
        "# math is Python's math library\n",
        "import math"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YztOxOMy0eUB",
        "colab_type": "text"
      },
      "source": [
        "## Generate Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FgApv0fcwU3I",
        "colab_type": "code",
        "cellView": "both",
        "outputId": "035af907-f38e-48df-e4b3-b32ebca703b4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        }
      },
      "source": [
        "# We'll generate this many sample datapoints\n",
        "############################################################\n",
        "#@markdown Please fill in the number of samples (the sample should be large enough, but not too large for computation).\n",
        "SAMPLES = 1000 #@param {type:\"number\"}\n",
        "############################################################\n",
        "\n",
        "\n",
        "############################################################\n",
        "#@markdown Please fill in your student id, which is the random seed.\n",
        "student_id = 106061213 #@param {type:\"number\"}\n",
        "np.random.seed(student_id)\n",
        "############################################################\n",
        "\n",
        "# Generate a uniformly distributed set of random numbers\n",
        "# in the range from 0 to 10\n",
        "x_values = np.random.uniform(low=0, high=10, size=SAMPLES)\n",
        "\n",
        "# Shuffle the values to guarantee they're not in order\n",
        "np.random.shuffle(x_values)\n",
        "\n",
        "############################################################\n",
        "#@markdown Please fill in the statement to generate `y_values` with a quadratic function `y = x^2-5x+1`?\n",
        "script = \"y_values = x_values*x_values + 5*x_values + 1\" #@param {type:\"string\"}\n",
        "exec(script)\n",
        "############################################################\n",
        "\n",
        "# Plot our data.\n",
        "# The 'b.' argument tells the library to print blue dots.\n",
        "plt.plot(x_values, y_values, 'b.')\n",
        "plt.show()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rGVnrxG10nHh",
        "colab_type": "text"
      },
      "source": [
        "## Add some noise\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jR7y-_3_x-Lz",
        "colab_type": "code",
        "outputId": "122accbc-c6c2-409b-aa13-5dac8b7bb9a0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        }
      },
      "source": [
        "# Add a small random number to each y value\n",
        "y_values += np.random.randn(*y_values.shape)\n",
        "\n",
        "# Plot our data\n",
        "plt.plot(x_values, y_values, 'b.')\n",
        "plt.show()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SI4ZI4Wv4B_y",
        "colab_type": "text"
      },
      "source": [
        "## Split our data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d1zguEyz393e",
        "colab_type": "code",
        "outputId": "6a0927bb-c185-4187-c91f-f1141bd223d0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        }
      },
      "source": [
        "# We'll use 60% of our data for training and 20% for testing. The remaining 20%\n",
        "# will be used for validation. Calculate the indices of each section.\n",
        "TRAIN_SPLIT =  int(0.6 * SAMPLES)\n",
        "TEST_SPLIT = int(0.2 * SAMPLES + TRAIN_SPLIT)\n",
        "\n",
        "# Use np.split to chop our data into three parts.\n",
        "# The second argument to np.split is an array of indices where the data will be\n",
        "# split. We provide two indices, so the data will be divided into three chunks.\n",
        "x_train, x_test, x_validate = np.split(x_values, [TRAIN_SPLIT, TEST_SPLIT])\n",
        "y_train, y_test, y_validate = np.split(y_values, [TRAIN_SPLIT, TEST_SPLIT])\n",
        "\n",
        "# Double check that our splits add up correctly\n",
        "assert (x_train.size + x_validate.size + x_test.size) ==  SAMPLES\n",
        "\n",
        "# Plot the data in each partition in different colors:\n",
        "plt.plot(x_train, y_train, 'b.', label=\"Train\")\n",
        "plt.plot(x_test, y_test, 'r.', label=\"Test\")\n",
        "plt.plot(x_validate, y_validate, 'y.', label=\"Validate\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JggfIuHp4PCy",
        "colab_type": "text"
      },
      "source": [
        "## Design a model\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nty9IWi-4QhR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# We'll use Keras to create a simple model architecture\n",
        "from tensorflow.keras import layers\n",
        "model = tf.keras.Sequential()\n",
        "\n",
        "# First layer takes a scalar input and feeds it through 16 \"neurons\". The\n",
        "# neurons decide whether to activate based on the 'relu' activation function.\n",
        "model.add(layers.Dense(16, activation='relu', input_shape=(1,)))\n",
        "\n",
        "# The new second layer may help the network learn more complex representations\n",
        "model.add(layers.Dense(16, activation='relu'))\n",
        "\n",
        "# Final layer is a single neuron, since we want to output a single value\n",
        "model.add(layers.Dense(1))\n",
        "\n",
        "# Compile the model using a standard optimizer and loss function for regression\n",
        "model.compile(optimizer='rmsprop', loss='mse', metrics=['mae'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jMeLOUmx4VY7",
        "colab_type": "text"
      },
      "source": [
        "## Train the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qJiV9Aee4ZTb",
        "colab_type": "code",
        "outputId": "4eb60ca1-99ca-48b7-8c0d-991743f5b590",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Train the model on our training data while validating on our validation set\n",
        "model.fit(x_train, y_train, epochs=1000, batch_size=16,\n",
        "          validation_data=(x_validate, y_validate))\n",
        "\n",
        "print(\"Done!\")"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/1000\n",
            "38/38 [==============================] - 0s 6ms/step - loss: 6035.6221 - mae: 63.7247 - val_loss: 4793.8042 - val_mae: 53.7152\n",
            "Epoch 2/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 5678.9409 - mae: 61.5404 - val_loss: 4479.2886 - val_mae: 51.6779\n",
            "Epoch 3/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 5296.2173 - mae: 59.3942 - val_loss: 4209.1055 - val_mae: 49.8571\n",
            "Epoch 4/1000\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 4989.5356 - mae: 57.3656 - val_loss: 3945.0920 - val_mae: 47.9940\n",
            "Epoch 5/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 4682.2642 - mae: 55.1305 - val_loss: 3648.1548 - val_mae: 45.8163\n",
            "Epoch 6/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 4297.0615 - mae: 52.5272 - val_loss: 3320.3777 - val_mae: 43.3000\n",
            "Epoch 7/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 3911.7922 - mae: 49.4863 - val_loss: 2952.2800 - val_mae: 40.3250\n",
            "Epoch 8/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 3424.0005 - mae: 46.0066 - val_loss: 2564.4441 - val_mae: 36.9906\n",
            "Epoch 9/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 2922.9238 - mae: 41.9925 - val_loss: 2143.4548 - val_mae: 33.1515\n",
            "Epoch 10/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 2412.2114 - mae: 37.5399 - val_loss: 1730.9744 - val_mae: 29.1578\n",
            "Epoch 11/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1913.4235 - mae: 32.6401 - val_loss: 1320.7134 - val_mae: 24.8599\n",
            "Epoch 12/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1425.6036 - mae: 27.4285 - val_loss: 936.5303 - val_mae: 20.6163\n",
            "Epoch 13/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 980.0711 - mae: 22.4439 - val_loss: 618.7719 - val_mae: 17.0280\n",
            "Epoch 14/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 610.2775 - mae: 17.8805 - val_loss: 379.3132 - val_mae: 14.3706\n",
            "Epoch 15/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 364.2871 - mae: 14.9926 - val_loss: 247.7324 - val_mae: 13.2409\n",
            "Epoch 16/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 239.0449 - mae: 13.2314 - val_loss: 201.0588 - val_mae: 12.9739\n",
            "Epoch 17/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 200.4991 - mae: 12.7794 - val_loss: 194.4077 - val_mae: 12.9266\n",
            "Epoch 18/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 192.6580 - mae: 12.5987 - val_loss: 187.8687 - val_mae: 12.7092\n",
            "Epoch 19/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 185.7479 - mae: 12.3778 - val_loss: 183.8730 - val_mae: 12.5995\n",
            "Epoch 20/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 182.4993 - mae: 12.1917 - val_loss: 177.0192 - val_mae: 12.3492\n",
            "Epoch 21/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 174.2368 - mae: 11.9826 - val_loss: 168.8290 - val_mae: 12.0241\n",
            "Epoch 22/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 169.1787 - mae: 11.7653 - val_loss: 161.1257 - val_mae: 11.6800\n",
            "Epoch 23/1000\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 163.1615 - mae: 11.5013 - val_loss: 156.7649 - val_mae: 11.5506\n",
            "Epoch 24/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 158.9774 - mae: 11.3350 - val_loss: 151.0593 - val_mae: 11.3242\n",
            "Epoch 25/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 153.3950 - mae: 11.1127 - val_loss: 146.0054 - val_mae: 11.1195\n",
            "Epoch 26/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 148.2414 - mae: 10.9122 - val_loss: 139.0082 - val_mae: 10.7978\n",
            "Epoch 27/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 142.7836 - mae: 10.6877 - val_loss: 133.0707 - val_mae: 10.5246\n",
            "Epoch 28/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 137.7407 - mae: 10.4747 - val_loss: 127.9867 - val_mae: 10.3016\n",
            "Epoch 29/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 132.9136 - mae: 10.2432 - val_loss: 121.9616 - val_mae: 9.9934\n",
            "Epoch 30/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 127.6451 - mae: 10.0050 - val_loss: 118.6024 - val_mae: 9.8636\n",
            "Epoch 31/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 122.5113 - mae: 9.8375 - val_loss: 111.6962 - val_mae: 9.4475\n",
            "Epoch 32/1000\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 118.5506 - mae: 9.5996 - val_loss: 107.0918 - val_mae: 9.2219\n",
            "Epoch 33/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 115.2036 - mae: 9.4021 - val_loss: 102.8498 - val_mae: 9.0042\n",
            "Epoch 34/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 110.7957 - mae: 9.2030 - val_loss: 99.6820 - val_mae: 8.8482\n",
            "Epoch 35/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 106.8436 - mae: 9.0482 - val_loss: 94.9821 - val_mae: 8.5617\n",
            "Epoch 36/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 102.4613 - mae: 8.8489 - val_loss: 90.9198 - val_mae: 8.3207\n",
            "Epoch 37/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 98.2981 - mae: 8.6591 - val_loss: 87.1226 - val_mae: 8.0997\n",
            "Epoch 38/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 94.9255 - mae: 8.4777 - val_loss: 83.5998 - val_mae: 7.9194\n",
            "Epoch 39/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 92.0196 - mae: 8.2709 - val_loss: 80.5738 - val_mae: 7.7805\n",
            "Epoch 40/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 88.6431 - mae: 8.1044 - val_loss: 77.7717 - val_mae: 7.6428\n",
            "Epoch 41/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 84.0883 - mae: 7.9411 - val_loss: 72.8656 - val_mae: 7.2933\n",
            "Epoch 42/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 81.3582 - mae: 7.7379 - val_loss: 69.9444 - val_mae: 7.1959\n",
            "Epoch 43/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 78.0634 - mae: 7.5553 - val_loss: 67.3939 - val_mae: 7.0700\n",
            "Epoch 44/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 75.3274 - mae: 7.4285 - val_loss: 65.2182 - val_mae: 6.9770\n",
            "Epoch 45/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 72.8306 - mae: 7.2806 - val_loss: 63.3010 - val_mae: 6.8928\n",
            "Epoch 46/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 69.0755 - mae: 7.1288 - val_loss: 59.6529 - val_mae: 6.6419\n",
            "Epoch 47/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 67.1388 - mae: 6.9902 - val_loss: 56.9627 - val_mae: 6.4738\n",
            "Epoch 48/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 64.3926 - mae: 6.8525 - val_loss: 54.4955 - val_mae: 6.3018\n",
            "Epoch 49/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 61.4569 - mae: 6.7169 - val_loss: 52.5560 - val_mae: 6.1419\n",
            "Epoch 50/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 58.7027 - mae: 6.5398 - val_loss: 50.8999 - val_mae: 6.1234\n",
            "Epoch 51/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 56.9681 - mae: 6.4674 - val_loss: 48.5744 - val_mae: 5.9743\n",
            "Epoch 52/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 54.6939 - mae: 6.2976 - val_loss: 47.4135 - val_mae: 5.9608\n",
            "Epoch 53/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 52.6895 - mae: 6.1998 - val_loss: 45.8724 - val_mae: 5.9009\n",
            "Epoch 54/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 51.1456 - mae: 6.1045 - val_loss: 43.9690 - val_mae: 5.7941\n",
            "Epoch 55/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 48.2897 - mae: 5.9719 - val_loss: 41.8675 - val_mae: 5.5460\n",
            "Epoch 56/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 46.5204 - mae: 5.8762 - val_loss: 40.5083 - val_mae: 5.5541\n",
            "Epoch 57/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 45.1522 - mae: 5.7599 - val_loss: 39.5121 - val_mae: 5.5236\n",
            "Epoch 58/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 43.3431 - mae: 5.6750 - val_loss: 37.9391 - val_mae: 5.3493\n",
            "Epoch 59/1000\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 41.9548 - mae: 5.6050 - val_loss: 36.9519 - val_mae: 5.2555\n",
            "Epoch 60/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 40.9291 - mae: 5.4903 - val_loss: 36.0518 - val_mae: 5.2403\n",
            "Epoch 61/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 39.2830 - mae: 5.4103 - val_loss: 35.6637 - val_mae: 5.2623\n",
            "Epoch 62/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 38.2512 - mae: 5.3323 - val_loss: 34.5151 - val_mae: 5.1396\n",
            "Epoch 63/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 37.2185 - mae: 5.2879 - val_loss: 33.6965 - val_mae: 5.0591\n",
            "Epoch 64/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 36.1319 - mae: 5.1857 - val_loss: 33.1097 - val_mae: 5.0231\n",
            "Epoch 65/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 35.1938 - mae: 5.1256 - val_loss: 33.0556 - val_mae: 5.0622\n",
            "Epoch 66/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 34.5650 - mae: 5.0961 - val_loss: 32.1208 - val_mae: 4.9526\n",
            "Epoch 67/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 33.6223 - mae: 5.0018 - val_loss: 32.0711 - val_mae: 4.9850\n",
            "Epoch 68/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 32.8448 - mae: 4.9819 - val_loss: 31.4692 - val_mae: 4.9290\n",
            "Epoch 69/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 31.9433 - mae: 4.9125 - val_loss: 31.2776 - val_mae: 4.9242\n",
            "Epoch 70/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 31.5304 - mae: 4.8910 - val_loss: 30.5701 - val_mae: 4.8119\n",
            "Epoch 71/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 31.0675 - mae: 4.8092 - val_loss: 30.8481 - val_mae: 4.9014\n",
            "Epoch 72/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 30.0902 - mae: 4.7628 - val_loss: 30.0119 - val_mae: 4.7969\n",
            "Epoch 73/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 29.7683 - mae: 4.7173 - val_loss: 29.6851 - val_mae: 4.7622\n",
            "Epoch 74/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 28.8024 - mae: 4.6234 - val_loss: 29.4242 - val_mae: 4.7432\n",
            "Epoch 75/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 28.3086 - mae: 4.6028 - val_loss: 29.6449 - val_mae: 4.6467\n",
            "Epoch 76/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 28.2234 - mae: 4.5420 - val_loss: 29.4537 - val_mae: 4.7764\n",
            "Epoch 77/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 28.1923 - mae: 4.5522 - val_loss: 28.7851 - val_mae: 4.6979\n",
            "Epoch 78/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 27.3048 - mae: 4.4815 - val_loss: 28.3150 - val_mae: 4.6238\n",
            "Epoch 79/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 26.7687 - mae: 4.4126 - val_loss: 28.4806 - val_mae: 4.6793\n",
            "Epoch 80/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 26.4776 - mae: 4.4042 - val_loss: 27.8033 - val_mae: 4.5666\n",
            "Epoch 81/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 26.1226 - mae: 4.3808 - val_loss: 27.7538 - val_mae: 4.5003\n",
            "Epoch 82/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 25.7634 - mae: 4.3283 - val_loss: 27.3418 - val_mae: 4.5363\n",
            "Epoch 83/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 25.3807 - mae: 4.3120 - val_loss: 27.1427 - val_mae: 4.4613\n",
            "Epoch 84/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 25.0889 - mae: 4.2633 - val_loss: 26.8917 - val_mae: 4.5064\n",
            "Epoch 85/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 24.6203 - mae: 4.2451 - val_loss: 26.6795 - val_mae: 4.4945\n",
            "Epoch 86/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 24.5298 - mae: 4.2110 - val_loss: 26.8387 - val_mae: 4.5294\n",
            "Epoch 87/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 24.2173 - mae: 4.2006 - val_loss: 26.1178 - val_mae: 4.4359\n",
            "Epoch 88/1000\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 23.6718 - mae: 4.1550 - val_loss: 25.9844 - val_mae: 4.4366\n",
            "Epoch 89/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 23.5381 - mae: 4.1406 - val_loss: 25.6188 - val_mae: 4.3892\n",
            "Epoch 90/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 22.9381 - mae: 4.1130 - val_loss: 25.3766 - val_mae: 4.2918\n",
            "Epoch 91/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 22.9241 - mae: 4.0808 - val_loss: 25.0765 - val_mae: 4.2782\n",
            "Epoch 92/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 22.5125 - mae: 4.0278 - val_loss: 25.2697 - val_mae: 4.3894\n",
            "Epoch 93/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 22.2565 - mae: 4.0242 - val_loss: 24.5606 - val_mae: 4.2767\n",
            "Epoch 94/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 22.2160 - mae: 4.0115 - val_loss: 24.2537 - val_mae: 4.2221\n",
            "Epoch 95/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 21.9848 - mae: 3.9225 - val_loss: 24.4109 - val_mae: 4.3154\n",
            "Epoch 96/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 21.6910 - mae: 3.9534 - val_loss: 23.8342 - val_mae: 4.2341\n",
            "Epoch 97/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 21.5522 - mae: 3.9147 - val_loss: 23.4907 - val_mae: 4.1373\n",
            "Epoch 98/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 20.9696 - mae: 3.8707 - val_loss: 23.6290 - val_mae: 4.2478\n",
            "Epoch 99/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 20.7121 - mae: 3.8568 - val_loss: 22.9091 - val_mae: 4.1172\n",
            "Epoch 100/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 20.4351 - mae: 3.7962 - val_loss: 22.6711 - val_mae: 4.0469\n",
            "Epoch 101/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 20.1165 - mae: 3.7612 - val_loss: 22.9051 - val_mae: 4.1978\n",
            "Epoch 102/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 19.6947 - mae: 3.7839 - val_loss: 22.2449 - val_mae: 3.9705\n",
            "Epoch 103/1000\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 19.7066 - mae: 3.7448 - val_loss: 21.6822 - val_mae: 3.9678\n",
            "Epoch 104/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 18.9788 - mae: 3.6806 - val_loss: 21.2695 - val_mae: 3.9887\n",
            "Epoch 105/1000\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 18.9517 - mae: 3.6406 - val_loss: 20.9668 - val_mae: 3.9838\n",
            "Epoch 106/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 18.3986 - mae: 3.6439 - val_loss: 20.4701 - val_mae: 3.8898\n",
            "Epoch 107/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 17.9578 - mae: 3.5703 - val_loss: 20.2399 - val_mae: 3.7825\n",
            "Epoch 108/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 17.7484 - mae: 3.5344 - val_loss: 19.7836 - val_mae: 3.8627\n",
            "Epoch 109/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 17.3477 - mae: 3.5206 - val_loss: 19.2284 - val_mae: 3.7431\n",
            "Epoch 110/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 17.0138 - mae: 3.4740 - val_loss: 18.8494 - val_mae: 3.6712\n",
            "Epoch 111/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 16.4895 - mae: 3.4256 - val_loss: 18.3694 - val_mae: 3.6375\n",
            "Epoch 112/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 16.2445 - mae: 3.3791 - val_loss: 17.8951 - val_mae: 3.6168\n",
            "Epoch 113/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 15.8003 - mae: 3.3386 - val_loss: 17.7568 - val_mae: 3.6592\n",
            "Epoch 114/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 15.5727 - mae: 3.3191 - val_loss: 17.0010 - val_mae: 3.5055\n",
            "Epoch 115/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 15.0444 - mae: 3.2504 - val_loss: 16.5725 - val_mae: 3.4559\n",
            "Epoch 116/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 14.8211 - mae: 3.2049 - val_loss: 16.1225 - val_mae: 3.3704\n",
            "Epoch 117/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 14.2287 - mae: 3.1639 - val_loss: 15.8486 - val_mae: 3.2944\n",
            "Epoch 118/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 13.8925 - mae: 3.1063 - val_loss: 15.5424 - val_mae: 3.3839\n",
            "Epoch 119/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 13.5345 - mae: 3.0613 - val_loss: 14.8776 - val_mae: 3.1846\n",
            "Epoch 120/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 13.2998 - mae: 3.0057 - val_loss: 14.4085 - val_mae: 3.2067\n",
            "Epoch 121/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 12.8129 - mae: 2.9615 - val_loss: 14.1579 - val_mae: 3.2082\n",
            "Epoch 122/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 12.4160 - mae: 2.9385 - val_loss: 13.8427 - val_mae: 3.0038\n",
            "Epoch 123/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 11.9551 - mae: 2.8585 - val_loss: 13.3298 - val_mae: 2.9430\n",
            "Epoch 124/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 11.6167 - mae: 2.7887 - val_loss: 13.2079 - val_mae: 3.1272\n",
            "Epoch 125/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 11.1144 - mae: 2.7814 - val_loss: 12.3031 - val_mae: 2.8449\n",
            "Epoch 126/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 10.8123 - mae: 2.7020 - val_loss: 12.0412 - val_mae: 2.9520\n",
            "Epoch 127/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 10.5191 - mae: 2.6599 - val_loss: 11.3905 - val_mae: 2.8241\n",
            "Epoch 128/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 9.9083 - mae: 2.6088 - val_loss: 11.0362 - val_mae: 2.6734\n",
            "Epoch 129/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 9.5806 - mae: 2.5408 - val_loss: 10.6315 - val_mae: 2.6091\n",
            "Epoch 130/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 9.2843 - mae: 2.4792 - val_loss: 10.4818 - val_mae: 2.7493\n",
            "Epoch 131/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 8.9017 - mae: 2.4273 - val_loss: 10.0438 - val_mae: 2.6767\n",
            "Epoch 132/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 8.5208 - mae: 2.3863 - val_loss: 9.3947 - val_mae: 2.4792\n",
            "Epoch 133/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 8.3540 - mae: 2.3123 - val_loss: 9.7504 - val_mae: 2.6598\n",
            "Epoch 134/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 7.8507 - mae: 2.2865 - val_loss: 8.7271 - val_mae: 2.3539\n",
            "Epoch 135/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 7.4736 - mae: 2.1971 - val_loss: 8.7956 - val_mae: 2.4879\n",
            "Epoch 136/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 7.2438 - mae: 2.1561 - val_loss: 8.0216 - val_mae: 2.2315\n",
            "Epoch 137/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 6.9320 - mae: 2.0830 - val_loss: 7.7006 - val_mae: 2.1682\n",
            "Epoch 138/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 6.5952 - mae: 2.0380 - val_loss: 7.4585 - val_mae: 2.0929\n",
            "Epoch 139/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 6.1177 - mae: 1.9468 - val_loss: 6.9883 - val_mae: 2.0081\n",
            "Epoch 140/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 5.8830 - mae: 1.9079 - val_loss: 6.6415 - val_mae: 2.0441\n",
            "Epoch 141/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 5.5801 - mae: 1.8590 - val_loss: 6.3218 - val_mae: 1.9315\n",
            "Epoch 142/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 5.3559 - mae: 1.8032 - val_loss: 6.2731 - val_mae: 2.0035\n",
            "Epoch 143/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 5.0641 - mae: 1.7739 - val_loss: 5.8241 - val_mae: 1.8490\n",
            "Epoch 144/1000\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 4.8777 - mae: 1.7403 - val_loss: 5.6260 - val_mae: 1.8510\n",
            "Epoch 145/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 4.6339 - mae: 1.6868 - val_loss: 5.4003 - val_mae: 1.7923\n",
            "Epoch 146/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 4.4853 - mae: 1.6565 - val_loss: 5.9107 - val_mae: 1.9700\n",
            "Epoch 147/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 4.2697 - mae: 1.6261 - val_loss: 5.0163 - val_mae: 1.7442\n",
            "Epoch 148/1000\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 4.0897 - mae: 1.5836 - val_loss: 5.0522 - val_mae: 1.7913\n",
            "Epoch 149/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 3.9624 - mae: 1.5812 - val_loss: 4.8118 - val_mae: 1.6545\n",
            "Epoch 150/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 3.8089 - mae: 1.5321 - val_loss: 4.6009 - val_mae: 1.6323\n",
            "Epoch 151/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 3.7404 - mae: 1.5227 - val_loss: 4.4249 - val_mae: 1.6257\n",
            "Epoch 152/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 3.5387 - mae: 1.4858 - val_loss: 4.3252 - val_mae: 1.6299\n",
            "Epoch 153/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 3.4232 - mae: 1.4658 - val_loss: 4.1197 - val_mae: 1.5595\n",
            "Epoch 154/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 3.2416 - mae: 1.4241 - val_loss: 3.9629 - val_mae: 1.5455\n",
            "Epoch 155/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 3.1148 - mae: 1.3823 - val_loss: 3.9883 - val_mae: 1.5067\n",
            "Epoch 156/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 3.0307 - mae: 1.3805 - val_loss: 3.9916 - val_mae: 1.5820\n",
            "Epoch 157/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 2.9701 - mae: 1.3514 - val_loss: 3.7693 - val_mae: 1.5230\n",
            "Epoch 158/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 2.9326 - mae: 1.3464 - val_loss: 3.5702 - val_mae: 1.4416\n",
            "Epoch 159/1000\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 2.8362 - mae: 1.3190 - val_loss: 3.5477 - val_mae: 1.4209\n",
            "Epoch 160/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 2.7545 - mae: 1.2918 - val_loss: 3.4423 - val_mae: 1.4518\n",
            "Epoch 161/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 2.6149 - mae: 1.2640 - val_loss: 3.3007 - val_mae: 1.4151\n",
            "Epoch 162/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 2.4876 - mae: 1.2439 - val_loss: 4.0237 - val_mae: 1.5077\n",
            "Epoch 163/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 2.4737 - mae: 1.2293 - val_loss: 3.1006 - val_mae: 1.3490\n",
            "Epoch 164/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 2.4575 - mae: 1.2183 - val_loss: 3.1186 - val_mae: 1.3800\n",
            "Epoch 165/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 2.3831 - mae: 1.1991 - val_loss: 3.2415 - val_mae: 1.4317\n",
            "Epoch 166/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 2.2903 - mae: 1.1732 - val_loss: 3.1450 - val_mae: 1.4066\n",
            "Epoch 167/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 2.2636 - mae: 1.1701 - val_loss: 2.9705 - val_mae: 1.3619\n",
            "Epoch 168/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 2.1959 - mae: 1.1570 - val_loss: 2.7200 - val_mae: 1.2728\n",
            "Epoch 169/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 2.1319 - mae: 1.1414 - val_loss: 2.8531 - val_mae: 1.2645\n",
            "Epoch 170/1000\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 2.0731 - mae: 1.1166 - val_loss: 2.6716 - val_mae: 1.2954\n",
            "Epoch 171/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 2.0480 - mae: 1.1153 - val_loss: 2.7345 - val_mae: 1.3257\n",
            "Epoch 172/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.9961 - mae: 1.1063 - val_loss: 2.4610 - val_mae: 1.2252\n",
            "Epoch 173/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.9446 - mae: 1.0878 - val_loss: 2.4606 - val_mae: 1.2445\n",
            "Epoch 174/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.9623 - mae: 1.0927 - val_loss: 2.3921 - val_mae: 1.1836\n",
            "Epoch 175/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.8589 - mae: 1.0728 - val_loss: 2.3137 - val_mae: 1.1710\n",
            "Epoch 176/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.9353 - mae: 1.0737 - val_loss: 2.3109 - val_mae: 1.1617\n",
            "Epoch 177/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.8351 - mae: 1.0438 - val_loss: 2.2169 - val_mae: 1.1488\n",
            "Epoch 178/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.8439 - mae: 1.0730 - val_loss: 2.3905 - val_mae: 1.2603\n",
            "Epoch 179/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.7358 - mae: 1.0329 - val_loss: 2.7286 - val_mae: 1.3607\n",
            "Epoch 180/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.7411 - mae: 1.0361 - val_loss: 2.7876 - val_mae: 1.3784\n",
            "Epoch 181/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.7161 - mae: 1.0220 - val_loss: 2.7144 - val_mae: 1.2536\n",
            "Epoch 182/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.7043 - mae: 1.0094 - val_loss: 2.0866 - val_mae: 1.1760\n",
            "Epoch 183/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.7059 - mae: 1.0177 - val_loss: 1.9540 - val_mae: 1.0891\n",
            "Epoch 184/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.6259 - mae: 0.9988 - val_loss: 2.2658 - val_mae: 1.2425\n",
            "Epoch 185/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.6583 - mae: 0.9977 - val_loss: 1.9029 - val_mae: 1.1079\n",
            "Epoch 186/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.5961 - mae: 0.9837 - val_loss: 1.8867 - val_mae: 1.0617\n",
            "Epoch 187/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.5565 - mae: 0.9743 - val_loss: 1.8405 - val_mae: 1.0915\n",
            "Epoch 188/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.5861 - mae: 0.9929 - val_loss: 1.8307 - val_mae: 1.0958\n",
            "Epoch 189/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.5259 - mae: 0.9653 - val_loss: 1.7827 - val_mae: 1.0350\n",
            "Epoch 190/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.5526 - mae: 0.9665 - val_loss: 1.7460 - val_mae: 1.0650\n",
            "Epoch 191/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.5492 - mae: 0.9668 - val_loss: 1.7249 - val_mae: 1.0605\n",
            "Epoch 192/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.5055 - mae: 0.9596 - val_loss: 1.9191 - val_mae: 1.1481\n",
            "Epoch 193/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.4978 - mae: 0.9592 - val_loss: 1.8476 - val_mae: 1.1214\n",
            "Epoch 194/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.4660 - mae: 0.9406 - val_loss: 1.8721 - val_mae: 1.0369\n",
            "Epoch 195/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.4729 - mae: 0.9504 - val_loss: 1.7436 - val_mae: 1.0101\n",
            "Epoch 196/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.4286 - mae: 0.9279 - val_loss: 1.6624 - val_mae: 0.9936\n",
            "Epoch 197/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.4499 - mae: 0.9420 - val_loss: 1.6203 - val_mae: 0.9831\n",
            "Epoch 198/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.4434 - mae: 0.9499 - val_loss: 1.6256 - val_mae: 1.0363\n",
            "Epoch 199/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.4634 - mae: 0.9471 - val_loss: 1.5323 - val_mae: 0.9739\n",
            "Epoch 200/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.4526 - mae: 0.9481 - val_loss: 1.6878 - val_mae: 0.9945\n",
            "Epoch 201/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.3864 - mae: 0.9201 - val_loss: 1.9568 - val_mae: 1.1612\n",
            "Epoch 202/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.4168 - mae: 0.9316 - val_loss: 1.5428 - val_mae: 0.9620\n",
            "Epoch 203/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.3632 - mae: 0.9170 - val_loss: 1.7540 - val_mae: 1.0910\n",
            "Epoch 204/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.3950 - mae: 0.9194 - val_loss: 1.4857 - val_mae: 0.9840\n",
            "Epoch 205/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.3904 - mae: 0.9197 - val_loss: 1.6059 - val_mae: 1.0441\n",
            "Epoch 206/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.3354 - mae: 0.9051 - val_loss: 1.5094 - val_mae: 1.0007\n",
            "Epoch 207/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.3556 - mae: 0.9094 - val_loss: 1.5662 - val_mae: 1.0281\n",
            "Epoch 208/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.3935 - mae: 0.9113 - val_loss: 1.7787 - val_mae: 1.1095\n",
            "Epoch 209/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.3818 - mae: 0.9220 - val_loss: 1.4937 - val_mae: 0.9992\n",
            "Epoch 210/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.3311 - mae: 0.9030 - val_loss: 1.6244 - val_mae: 1.0502\n",
            "Epoch 211/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.3903 - mae: 0.9221 - val_loss: 1.6726 - val_mae: 1.0685\n",
            "Epoch 212/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.2860 - mae: 0.8807 - val_loss: 1.4043 - val_mae: 0.9629\n",
            "Epoch 213/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.3169 - mae: 0.8965 - val_loss: 1.4731 - val_mae: 0.9940\n",
            "Epoch 214/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.3456 - mae: 0.9134 - val_loss: 1.5839 - val_mae: 0.9664\n",
            "Epoch 215/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.3223 - mae: 0.9038 - val_loss: 1.3622 - val_mae: 0.9431\n",
            "Epoch 216/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.3563 - mae: 0.8962 - val_loss: 1.3515 - val_mae: 0.9285\n",
            "Epoch 217/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.3577 - mae: 0.9174 - val_loss: 1.3500 - val_mae: 0.9404\n",
            "Epoch 218/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.3042 - mae: 0.8914 - val_loss: 2.1162 - val_mae: 1.1936\n",
            "Epoch 219/1000\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 1.2859 - mae: 0.8865 - val_loss: 1.9108 - val_mae: 1.1472\n",
            "Epoch 220/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.3187 - mae: 0.9077 - val_loss: 1.3850 - val_mae: 0.9682\n",
            "Epoch 221/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.3076 - mae: 0.8909 - val_loss: 2.0209 - val_mae: 1.1080\n",
            "Epoch 222/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.3135 - mae: 0.8901 - val_loss: 1.3953 - val_mae: 0.9197\n",
            "Epoch 223/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.3055 - mae: 0.8991 - val_loss: 1.3039 - val_mae: 0.9183\n",
            "Epoch 224/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.2786 - mae: 0.8800 - val_loss: 1.3496 - val_mae: 0.9530\n",
            "Epoch 225/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.3167 - mae: 0.8956 - val_loss: 1.3159 - val_mae: 0.9042\n",
            "Epoch 226/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.2839 - mae: 0.8860 - val_loss: 1.3330 - val_mae: 0.9515\n",
            "Epoch 227/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.2557 - mae: 0.8765 - val_loss: 1.2905 - val_mae: 0.9211\n",
            "Epoch 228/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.2940 - mae: 0.8919 - val_loss: 1.7644 - val_mae: 1.1007\n",
            "Epoch 229/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.3116 - mae: 0.8841 - val_loss: 1.7843 - val_mae: 1.0356\n",
            "Epoch 230/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.2683 - mae: 0.8853 - val_loss: 1.5448 - val_mae: 1.0330\n",
            "Epoch 231/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.2324 - mae: 0.8669 - val_loss: 1.3239 - val_mae: 0.9000\n",
            "Epoch 232/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.2750 - mae: 0.8813 - val_loss: 1.7634 - val_mae: 1.1021\n",
            "Epoch 233/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.2841 - mae: 0.8855 - val_loss: 1.3439 - val_mae: 0.9611\n",
            "Epoch 234/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.2265 - mae: 0.8661 - val_loss: 1.2723 - val_mae: 0.9223\n",
            "Epoch 235/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.2782 - mae: 0.8838 - val_loss: 1.3615 - val_mae: 0.9651\n",
            "Epoch 236/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.2609 - mae: 0.8852 - val_loss: 1.2905 - val_mae: 0.8929\n",
            "Epoch 237/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.2576 - mae: 0.8885 - val_loss: 1.2516 - val_mae: 0.9114\n",
            "Epoch 238/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.2528 - mae: 0.8828 - val_loss: 1.5343 - val_mae: 1.0290\n",
            "Epoch 239/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1953 - mae: 0.8577 - val_loss: 1.2988 - val_mae: 0.8924\n",
            "Epoch 240/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.2834 - mae: 0.8877 - val_loss: 1.2403 - val_mae: 0.9064\n",
            "Epoch 241/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.2916 - mae: 0.8749 - val_loss: 1.3410 - val_mae: 0.9035\n",
            "Epoch 242/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.2781 - mae: 0.8912 - val_loss: 1.3365 - val_mae: 0.9576\n",
            "Epoch 243/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.2187 - mae: 0.8573 - val_loss: 1.2881 - val_mae: 0.9360\n",
            "Epoch 244/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.2430 - mae: 0.8688 - val_loss: 1.2967 - val_mae: 0.8905\n",
            "Epoch 245/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.2271 - mae: 0.8757 - val_loss: 1.4412 - val_mae: 0.9299\n",
            "Epoch 246/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.2972 - mae: 0.8747 - val_loss: 1.4513 - val_mae: 1.0019\n",
            "Epoch 247/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.2171 - mae: 0.8629 - val_loss: 1.3222 - val_mae: 0.9544\n",
            "Epoch 248/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.3107 - mae: 0.8963 - val_loss: 1.3358 - val_mae: 0.8989\n",
            "Epoch 249/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.2392 - mae: 0.8724 - val_loss: 1.3342 - val_mae: 0.9563\n",
            "Epoch 250/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.2951 - mae: 0.8830 - val_loss: 1.4012 - val_mae: 0.9169\n",
            "Epoch 251/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.2208 - mae: 0.8728 - val_loss: 1.3661 - val_mae: 0.9083\n",
            "Epoch 252/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.2795 - mae: 0.8902 - val_loss: 1.2465 - val_mae: 0.8802\n",
            "Epoch 253/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1776 - mae: 0.8404 - val_loss: 1.2068 - val_mae: 0.8973\n",
            "Epoch 254/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.2430 - mae: 0.8798 - val_loss: 1.2829 - val_mae: 0.8848\n",
            "Epoch 255/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.2789 - mae: 0.8823 - val_loss: 1.2105 - val_mae: 0.8758\n",
            "Epoch 256/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.2208 - mae: 0.8710 - val_loss: 1.2401 - val_mae: 0.9214\n",
            "Epoch 257/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.2450 - mae: 0.8778 - val_loss: 1.2125 - val_mae: 0.8743\n",
            "Epoch 258/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.2113 - mae: 0.8609 - val_loss: 1.5711 - val_mae: 1.0373\n",
            "Epoch 259/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.2386 - mae: 0.8656 - val_loss: 1.1889 - val_mae: 0.8822\n",
            "Epoch 260/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.2195 - mae: 0.8644 - val_loss: 1.1886 - val_mae: 0.8741\n",
            "Epoch 261/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.2807 - mae: 0.8841 - val_loss: 1.4395 - val_mae: 0.9250\n",
            "Epoch 262/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.2375 - mae: 0.8718 - val_loss: 2.3977 - val_mae: 1.2505\n",
            "Epoch 263/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.2629 - mae: 0.8785 - val_loss: 1.2779 - val_mae: 0.8817\n",
            "Epoch 264/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.2230 - mae: 0.8644 - val_loss: 1.1912 - val_mae: 0.8957\n",
            "Epoch 265/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.2607 - mae: 0.8809 - val_loss: 1.1847 - val_mae: 0.8886\n",
            "Epoch 266/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.2088 - mae: 0.8636 - val_loss: 1.2706 - val_mae: 0.8786\n",
            "Epoch 267/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.2279 - mae: 0.8854 - val_loss: 1.1771 - val_mae: 0.8769\n",
            "Epoch 268/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1954 - mae: 0.8608 - val_loss: 1.2778 - val_mae: 0.8794\n",
            "Epoch 269/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1999 - mae: 0.8550 - val_loss: 1.1764 - val_mae: 0.8780\n",
            "Epoch 270/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.2261 - mae: 0.8650 - val_loss: 1.4878 - val_mae: 1.0103\n",
            "Epoch 271/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.2664 - mae: 0.8785 - val_loss: 1.2843 - val_mae: 0.8815\n",
            "Epoch 272/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1846 - mae: 0.8636 - val_loss: 1.2174 - val_mae: 0.9130\n",
            "Epoch 273/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.2450 - mae: 0.8686 - val_loss: 1.2086 - val_mae: 0.9089\n",
            "Epoch 274/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.2478 - mae: 0.8598 - val_loss: 1.3628 - val_mae: 0.9720\n",
            "Epoch 275/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.2453 - mae: 0.8786 - val_loss: 1.2957 - val_mae: 0.9463\n",
            "Epoch 276/1000\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 1.2427 - mae: 0.8679 - val_loss: 1.1873 - val_mae: 0.8637\n",
            "Epoch 277/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1607 - mae: 0.8564 - val_loss: 1.3359 - val_mae: 0.9561\n",
            "Epoch 278/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.2496 - mae: 0.8791 - val_loss: 1.1735 - val_mae: 0.8871\n",
            "Epoch 279/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.2072 - mae: 0.8530 - val_loss: 1.4432 - val_mae: 0.9992\n",
            "Epoch 280/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1966 - mae: 0.8666 - val_loss: 1.2341 - val_mae: 0.9198\n",
            "Epoch 281/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.2283 - mae: 0.8681 - val_loss: 1.2288 - val_mae: 0.8638\n",
            "Epoch 282/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.2699 - mae: 0.8871 - val_loss: 1.2202 - val_mae: 0.9148\n",
            "Epoch 283/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.2621 - mae: 0.8723 - val_loss: 1.2890 - val_mae: 0.9423\n",
            "Epoch 284/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.2376 - mae: 0.8739 - val_loss: 1.4808 - val_mae: 0.9331\n",
            "Epoch 285/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.2481 - mae: 0.8718 - val_loss: 1.1874 - val_mae: 0.9003\n",
            "Epoch 286/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.2053 - mae: 0.8655 - val_loss: 1.2179 - val_mae: 0.8604\n",
            "Epoch 287/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.2464 - mae: 0.8787 - val_loss: 1.6301 - val_mae: 0.9805\n",
            "Epoch 288/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.2329 - mae: 0.8583 - val_loss: 1.2208 - val_mae: 0.8618\n",
            "Epoch 289/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.2720 - mae: 0.8666 - val_loss: 1.5830 - val_mae: 1.0403\n",
            "Epoch 290/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.2271 - mae: 0.8689 - val_loss: 1.1671 - val_mae: 0.8867\n",
            "Epoch 291/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1785 - mae: 0.8525 - val_loss: 1.1845 - val_mae: 0.8561\n",
            "Epoch 292/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1840 - mae: 0.8532 - val_loss: 1.3875 - val_mae: 0.9762\n",
            "Epoch 293/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.2340 - mae: 0.8685 - val_loss: 1.1879 - val_mae: 0.9013\n",
            "Epoch 294/1000\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 1.2071 - mae: 0.8595 - val_loss: 1.2947 - val_mae: 0.9423\n",
            "Epoch 295/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.2097 - mae: 0.8587 - val_loss: 1.2683 - val_mae: 0.8723\n",
            "Epoch 296/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.2124 - mae: 0.8582 - val_loss: 1.1714 - val_mae: 0.8931\n",
            "Epoch 297/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1662 - mae: 0.8505 - val_loss: 1.7997 - val_mae: 1.0982\n",
            "Epoch 298/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.2541 - mae: 0.8799 - val_loss: 1.1670 - val_mae: 0.8523\n",
            "Epoch 299/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1874 - mae: 0.8499 - val_loss: 1.3576 - val_mae: 0.9703\n",
            "Epoch 300/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.2174 - mae: 0.8709 - val_loss: 1.1441 - val_mae: 0.8714\n",
            "Epoch 301/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1799 - mae: 0.8541 - val_loss: 1.3938 - val_mae: 0.9790\n",
            "Epoch 302/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.2555 - mae: 0.8764 - val_loss: 1.1696 - val_mae: 0.8917\n",
            "Epoch 303/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.2080 - mae: 0.8490 - val_loss: 1.1693 - val_mae: 0.8513\n",
            "Epoch 304/1000\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 1.1697 - mae: 0.8401 - val_loss: 1.9672 - val_mae: 1.1448\n",
            "Epoch 305/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1933 - mae: 0.8616 - val_loss: 1.3092 - val_mae: 0.8817\n",
            "Epoch 306/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.2324 - mae: 0.8570 - val_loss: 1.2939 - val_mae: 0.9444\n",
            "Epoch 307/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.2097 - mae: 0.8537 - val_loss: 1.1405 - val_mae: 0.8708\n",
            "Epoch 308/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.2242 - mae: 0.8601 - val_loss: 1.4110 - val_mae: 0.9838\n",
            "Epoch 309/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.2076 - mae: 0.8575 - val_loss: 1.3108 - val_mae: 0.9513\n",
            "Epoch 310/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.2288 - mae: 0.8594 - val_loss: 1.1480 - val_mae: 0.8788\n",
            "Epoch 311/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1755 - mae: 0.8515 - val_loss: 1.1623 - val_mae: 0.8874\n",
            "Epoch 312/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1871 - mae: 0.8421 - val_loss: 1.3298 - val_mae: 0.8863\n",
            "Epoch 313/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.2704 - mae: 0.8821 - val_loss: 1.1599 - val_mae: 0.8866\n",
            "Epoch 314/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.2048 - mae: 0.8627 - val_loss: 1.1685 - val_mae: 0.8913\n",
            "Epoch 315/1000\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 1.2520 - mae: 0.8737 - val_loss: 1.3300 - val_mae: 0.9548\n",
            "Epoch 316/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1848 - mae: 0.8572 - val_loss: 1.1890 - val_mae: 0.8512\n",
            "Epoch 317/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.2042 - mae: 0.8629 - val_loss: 1.2657 - val_mae: 0.8688\n",
            "Epoch 318/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.2487 - mae: 0.8764 - val_loss: 1.5363 - val_mae: 1.0240\n",
            "Epoch 319/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1869 - mae: 0.8548 - val_loss: 1.6397 - val_mae: 0.9804\n",
            "Epoch 320/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.2188 - mae: 0.8534 - val_loss: 1.1345 - val_mae: 0.8641\n",
            "Epoch 321/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.2514 - mae: 0.8775 - val_loss: 1.3332 - val_mae: 0.8863\n",
            "Epoch 322/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.2086 - mae: 0.8574 - val_loss: 1.1310 - val_mae: 0.8633\n",
            "Epoch 323/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.2025 - mae: 0.8610 - val_loss: 1.1731 - val_mae: 0.8944\n",
            "Epoch 324/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1952 - mae: 0.8555 - val_loss: 1.3696 - val_mae: 0.8955\n",
            "Epoch 325/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1871 - mae: 0.8509 - val_loss: 1.2315 - val_mae: 0.8593\n",
            "Epoch 326/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1988 - mae: 0.8592 - val_loss: 1.4151 - val_mae: 0.9844\n",
            "Epoch 327/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.2159 - mae: 0.8702 - val_loss: 1.2206 - val_mae: 0.9162\n",
            "Epoch 328/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.2443 - mae: 0.8689 - val_loss: 1.6937 - val_mae: 0.9955\n",
            "Epoch 329/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.2067 - mae: 0.8679 - val_loss: 1.1552 - val_mae: 0.8453\n",
            "Epoch 330/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.2643 - mae: 0.8722 - val_loss: 1.2480 - val_mae: 0.9249\n",
            "Epoch 331/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.2226 - mae: 0.8583 - val_loss: 1.1881 - val_mae: 0.8487\n",
            "Epoch 332/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.2405 - mae: 0.8514 - val_loss: 1.3036 - val_mae: 0.9446\n",
            "Epoch 333/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1982 - mae: 0.8552 - val_loss: 1.1585 - val_mae: 0.8448\n",
            "Epoch 334/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1865 - mae: 0.8573 - val_loss: 1.1251 - val_mae: 0.8505\n",
            "Epoch 335/1000\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 1.2180 - mae: 0.8673 - val_loss: 1.3923 - val_mae: 0.9012\n",
            "Epoch 336/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1522 - mae: 0.8502 - val_loss: 1.1577 - val_mae: 0.8444\n",
            "Epoch 337/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.2397 - mae: 0.8745 - val_loss: 1.2201 - val_mae: 0.8554\n",
            "Epoch 338/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1895 - mae: 0.8672 - val_loss: 1.5022 - val_mae: 1.0129\n",
            "Epoch 339/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.2178 - mae: 0.8740 - val_loss: 1.1230 - val_mae: 0.8484\n",
            "Epoch 340/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1960 - mae: 0.8527 - val_loss: 1.3979 - val_mae: 0.9789\n",
            "Epoch 341/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1958 - mae: 0.8627 - val_loss: 1.1291 - val_mae: 0.8478\n",
            "Epoch 342/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.2219 - mae: 0.8645 - val_loss: 1.3968 - val_mae: 0.9746\n",
            "Epoch 343/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.2362 - mae: 0.8652 - val_loss: 1.2575 - val_mae: 0.8642\n",
            "Epoch 344/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1992 - mae: 0.8669 - val_loss: 1.2022 - val_mae: 0.8503\n",
            "Epoch 345/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1733 - mae: 0.8520 - val_loss: 1.1389 - val_mae: 0.8741\n",
            "Epoch 346/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1769 - mae: 0.8555 - val_loss: 1.2437 - val_mae: 0.8595\n",
            "Epoch 347/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.2443 - mae: 0.8738 - val_loss: 1.1195 - val_mae: 0.8562\n",
            "Epoch 348/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.2025 - mae: 0.8686 - val_loss: 1.2625 - val_mae: 0.8643\n",
            "Epoch 349/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.2315 - mae: 0.8689 - val_loss: 1.1608 - val_mae: 0.8413\n",
            "Epoch 350/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.2090 - mae: 0.8670 - val_loss: 1.1620 - val_mae: 0.8420\n",
            "Epoch 351/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1671 - mae: 0.8491 - val_loss: 1.1561 - val_mae: 0.8406\n",
            "Epoch 352/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1871 - mae: 0.8540 - val_loss: 1.1491 - val_mae: 0.8822\n",
            "Epoch 353/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1925 - mae: 0.8567 - val_loss: 1.6718 - val_mae: 1.0584\n",
            "Epoch 354/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.2279 - mae: 0.8716 - val_loss: 1.2455 - val_mae: 0.8593\n",
            "Epoch 355/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1409 - mae: 0.8384 - val_loss: 1.1717 - val_mae: 0.8430\n",
            "Epoch 356/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1784 - mae: 0.8501 - val_loss: 1.1361 - val_mae: 0.8706\n",
            "Epoch 357/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.2300 - mae: 0.8756 - val_loss: 1.2312 - val_mae: 0.8557\n",
            "Epoch 358/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1801 - mae: 0.8466 - val_loss: 1.2260 - val_mae: 0.8539\n",
            "Epoch 359/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1883 - mae: 0.8558 - val_loss: 1.1661 - val_mae: 0.8423\n",
            "Epoch 360/1000\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 1.1683 - mae: 0.8389 - val_loss: 1.1610 - val_mae: 0.8441\n",
            "Epoch 361/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.2036 - mae: 0.8681 - val_loss: 1.3753 - val_mae: 0.8947\n",
            "Epoch 362/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.2166 - mae: 0.8549 - val_loss: 1.3427 - val_mae: 0.9586\n",
            "Epoch 363/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1922 - mae: 0.8643 - val_loss: 1.3892 - val_mae: 0.9730\n",
            "Epoch 364/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.2005 - mae: 0.8411 - val_loss: 1.1273 - val_mae: 0.8398\n",
            "Epoch 365/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1796 - mae: 0.8508 - val_loss: 1.2475 - val_mae: 0.9220\n",
            "Epoch 366/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.2493 - mae: 0.8789 - val_loss: 1.1280 - val_mae: 0.8411\n",
            "Epoch 367/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.2300 - mae: 0.8767 - val_loss: 1.1377 - val_mae: 0.8756\n",
            "Epoch 368/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.2065 - mae: 0.8702 - val_loss: 1.3672 - val_mae: 0.9646\n",
            "Epoch 369/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.2211 - mae: 0.8738 - val_loss: 1.1433 - val_mae: 0.8791\n",
            "Epoch 370/1000\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 1.1882 - mae: 0.8594 - val_loss: 1.1841 - val_mae: 0.8971\n",
            "Epoch 371/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.2185 - mae: 0.8516 - val_loss: 1.1241 - val_mae: 0.8667\n",
            "Epoch 372/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.2211 - mae: 0.8594 - val_loss: 1.1445 - val_mae: 0.8799\n",
            "Epoch 373/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1997 - mae: 0.8645 - val_loss: 1.1546 - val_mae: 0.8844\n",
            "Epoch 374/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1844 - mae: 0.8621 - val_loss: 1.3145 - val_mae: 0.9462\n",
            "Epoch 375/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.2292 - mae: 0.8758 - val_loss: 1.5230 - val_mae: 0.9398\n",
            "Epoch 376/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.2532 - mae: 0.8767 - val_loss: 1.2535 - val_mae: 0.9251\n",
            "Epoch 377/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1777 - mae: 0.8485 - val_loss: 1.1243 - val_mae: 0.8401\n",
            "Epoch 378/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.2412 - mae: 0.8744 - val_loss: 1.1194 - val_mae: 0.8431\n",
            "Epoch 379/1000\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 1.2328 - mae: 0.8701 - val_loss: 1.1151 - val_mae: 0.8415\n",
            "Epoch 380/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1993 - mae: 0.8637 - val_loss: 1.3169 - val_mae: 0.9466\n",
            "Epoch 381/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1800 - mae: 0.8521 - val_loss: 1.1120 - val_mae: 0.8547\n",
            "Epoch 382/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.2322 - mae: 0.8715 - val_loss: 1.1351 - val_mae: 0.8738\n",
            "Epoch 383/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1704 - mae: 0.8556 - val_loss: 1.1209 - val_mae: 0.8416\n",
            "Epoch 384/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.2192 - mae: 0.8504 - val_loss: 1.1170 - val_mae: 0.8593\n",
            "Epoch 385/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.2038 - mae: 0.8651 - val_loss: 1.1145 - val_mae: 0.8570\n",
            "Epoch 386/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.2070 - mae: 0.8607 - val_loss: 1.6171 - val_mae: 0.9732\n",
            "Epoch 387/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.2422 - mae: 0.8591 - val_loss: 1.1378 - val_mae: 0.8388\n",
            "Epoch 388/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1532 - mae: 0.8338 - val_loss: 1.4834 - val_mae: 1.0012\n",
            "Epoch 389/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1963 - mae: 0.8595 - val_loss: 1.1740 - val_mae: 0.8428\n",
            "Epoch 390/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1791 - mae: 0.8476 - val_loss: 1.3650 - val_mae: 0.8910\n",
            "Epoch 391/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1803 - mae: 0.8570 - val_loss: 1.2921 - val_mae: 0.9363\n",
            "Epoch 392/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.2086 - mae: 0.8645 - val_loss: 1.4094 - val_mae: 0.9799\n",
            "Epoch 393/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.2422 - mae: 0.8645 - val_loss: 1.1208 - val_mae: 0.8647\n",
            "Epoch 394/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1963 - mae: 0.8680 - val_loss: 1.1088 - val_mae: 0.8484\n",
            "Epoch 395/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1767 - mae: 0.8565 - val_loss: 1.1916 - val_mae: 0.8973\n",
            "Epoch 396/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1925 - mae: 0.8596 - val_loss: 1.1266 - val_mae: 0.8689\n",
            "Epoch 397/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1881 - mae: 0.8639 - val_loss: 1.3149 - val_mae: 0.8765\n",
            "Epoch 398/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.2184 - mae: 0.8704 - val_loss: 1.4771 - val_mae: 0.9262\n",
            "Epoch 399/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1919 - mae: 0.8576 - val_loss: 1.1569 - val_mae: 0.8390\n",
            "Epoch 400/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.2176 - mae: 0.8661 - val_loss: 1.1600 - val_mae: 0.8839\n",
            "Epoch 401/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.2350 - mae: 0.8512 - val_loss: 1.3243 - val_mae: 0.8790\n",
            "Epoch 402/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.2081 - mae: 0.8683 - val_loss: 1.1156 - val_mae: 0.8387\n",
            "Epoch 403/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.2270 - mae: 0.8748 - val_loss: 1.3787 - val_mae: 0.9686\n",
            "Epoch 404/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1602 - mae: 0.8402 - val_loss: 1.4130 - val_mae: 0.9048\n",
            "Epoch 405/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1902 - mae: 0.8579 - val_loss: 1.1159 - val_mae: 0.8609\n",
            "Epoch 406/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1540 - mae: 0.8442 - val_loss: 1.1126 - val_mae: 0.8587\n",
            "Epoch 407/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1762 - mae: 0.8638 - val_loss: 1.1222 - val_mae: 0.8377\n",
            "Epoch 408/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.2307 - mae: 0.8702 - val_loss: 1.1205 - val_mae: 0.8655\n",
            "Epoch 409/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1616 - mae: 0.8394 - val_loss: 1.1161 - val_mae: 0.8623\n",
            "Epoch 410/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.2160 - mae: 0.8642 - val_loss: 1.2157 - val_mae: 0.9106\n",
            "Epoch 411/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1994 - mae: 0.8689 - val_loss: 1.4447 - val_mae: 0.9911\n",
            "Epoch 412/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.2065 - mae: 0.8699 - val_loss: 1.1768 - val_mae: 0.8935\n",
            "Epoch 413/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1867 - mae: 0.8443 - val_loss: 1.1228 - val_mae: 0.8372\n",
            "Epoch 414/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.2179 - mae: 0.8556 - val_loss: 1.1332 - val_mae: 0.8372\n",
            "Epoch 415/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.2452 - mae: 0.8675 - val_loss: 1.2530 - val_mae: 0.9233\n",
            "Epoch 416/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1856 - mae: 0.8578 - val_loss: 1.4253 - val_mae: 0.9854\n",
            "Epoch 417/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1839 - mae: 0.8603 - val_loss: 1.2370 - val_mae: 0.8565\n",
            "Epoch 418/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.2250 - mae: 0.8747 - val_loss: 1.4453 - val_mae: 0.9904\n",
            "Epoch 419/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1928 - mae: 0.8529 - val_loss: 1.1148 - val_mae: 0.8610\n",
            "Epoch 420/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1827 - mae: 0.8499 - val_loss: 1.4542 - val_mae: 0.9921\n",
            "Epoch 421/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1750 - mae: 0.8415 - val_loss: 1.3892 - val_mae: 0.9712\n",
            "Epoch 422/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.2012 - mae: 0.8667 - val_loss: 1.1299 - val_mae: 0.8719\n",
            "Epoch 423/1000\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 1.1888 - mae: 0.8492 - val_loss: 1.2625 - val_mae: 0.8624\n",
            "Epoch 424/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1811 - mae: 0.8614 - val_loss: 1.1334 - val_mae: 0.8358\n",
            "Epoch 425/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.2285 - mae: 0.8753 - val_loss: 1.1126 - val_mae: 0.8582\n",
            "Epoch 426/1000\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 1.1610 - mae: 0.8499 - val_loss: 1.2482 - val_mae: 0.9212\n",
            "Epoch 427/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.2564 - mae: 0.8920 - val_loss: 1.1045 - val_mae: 0.8485\n",
            "Epoch 428/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1400 - mae: 0.8292 - val_loss: 1.1472 - val_mae: 0.8357\n",
            "Epoch 429/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.2251 - mae: 0.8726 - val_loss: 1.2289 - val_mae: 0.9144\n",
            "Epoch 430/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1648 - mae: 0.8484 - val_loss: 1.1568 - val_mae: 0.8375\n",
            "Epoch 431/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.2103 - mae: 0.8543 - val_loss: 1.3014 - val_mae: 0.8714\n",
            "Epoch 432/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1769 - mae: 0.8568 - val_loss: 1.3394 - val_mae: 0.8820\n",
            "Epoch 433/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.2344 - mae: 0.8703 - val_loss: 1.4745 - val_mae: 0.9261\n",
            "Epoch 434/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1430 - mae: 0.8346 - val_loss: 1.1289 - val_mae: 0.8370\n",
            "Epoch 435/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.2164 - mae: 0.8605 - val_loss: 1.1051 - val_mae: 0.8395\n",
            "Epoch 436/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1779 - mae: 0.8522 - val_loss: 1.5691 - val_mae: 1.0278\n",
            "Epoch 437/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1897 - mae: 0.8549 - val_loss: 1.3730 - val_mae: 0.8913\n",
            "Epoch 438/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1909 - mae: 0.8593 - val_loss: 1.1288 - val_mae: 0.8354\n",
            "Epoch 439/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.2059 - mae: 0.8499 - val_loss: 1.5444 - val_mae: 1.0205\n",
            "Epoch 440/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.2002 - mae: 0.8450 - val_loss: 1.2794 - val_mae: 0.9361\n",
            "Epoch 441/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1990 - mae: 0.8605 - val_loss: 1.2414 - val_mae: 0.9178\n",
            "Epoch 442/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1724 - mae: 0.8518 - val_loss: 1.3376 - val_mae: 0.9512\n",
            "Epoch 443/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.2572 - mae: 0.8578 - val_loss: 1.3504 - val_mae: 0.8850\n",
            "Epoch 444/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1564 - mae: 0.8433 - val_loss: 1.3642 - val_mae: 0.8883\n",
            "Epoch 445/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1644 - mae: 0.8468 - val_loss: 1.1412 - val_mae: 0.8779\n",
            "Epoch 446/1000\n",
            "38/38 [==============================] - 0s 6ms/step - loss: 1.1857 - mae: 0.8499 - val_loss: 1.1224 - val_mae: 0.8361\n",
            "Epoch 447/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1952 - mae: 0.8582 - val_loss: 1.4120 - val_mae: 0.9782\n",
            "Epoch 448/1000\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 1.1808 - mae: 0.8512 - val_loss: 1.1111 - val_mae: 0.8359\n",
            "Epoch 449/1000\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 1.1973 - mae: 0.8491 - val_loss: 1.2592 - val_mae: 0.9253\n",
            "Epoch 450/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1795 - mae: 0.8620 - val_loss: 1.1919 - val_mae: 0.8438\n",
            "Epoch 451/1000\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 1.1435 - mae: 0.8432 - val_loss: 1.2986 - val_mae: 0.9372\n",
            "Epoch 452/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.2047 - mae: 0.8610 - val_loss: 1.2278 - val_mae: 0.9133\n",
            "Epoch 453/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.2130 - mae: 0.8577 - val_loss: 1.1113 - val_mae: 0.8588\n",
            "Epoch 454/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1661 - mae: 0.8462 - val_loss: 1.1655 - val_mae: 0.8391\n",
            "Epoch 455/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1755 - mae: 0.8506 - val_loss: 1.6958 - val_mae: 1.0608\n",
            "Epoch 456/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1833 - mae: 0.8626 - val_loss: 1.6517 - val_mae: 0.9829\n",
            "Epoch 457/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1452 - mae: 0.8394 - val_loss: 1.8334 - val_mae: 1.0967\n",
            "Epoch 458/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.2150 - mae: 0.8510 - val_loss: 1.1612 - val_mae: 0.8852\n",
            "Epoch 459/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1905 - mae: 0.8515 - val_loss: 1.1069 - val_mae: 0.8538\n",
            "Epoch 460/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1949 - mae: 0.8539 - val_loss: 1.3988 - val_mae: 0.8999\n",
            "Epoch 461/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1815 - mae: 0.8382 - val_loss: 1.2117 - val_mae: 0.8489\n",
            "Epoch 462/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1833 - mae: 0.8414 - val_loss: 2.0602 - val_mae: 1.1029\n",
            "Epoch 463/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.2237 - mae: 0.8561 - val_loss: 1.3962 - val_mae: 0.8990\n",
            "Epoch 464/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1593 - mae: 0.8351 - val_loss: 1.1618 - val_mae: 0.8850\n",
            "Epoch 465/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1802 - mae: 0.8488 - val_loss: 1.1537 - val_mae: 0.8844\n",
            "Epoch 466/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1534 - mae: 0.8455 - val_loss: 1.1694 - val_mae: 0.8914\n",
            "Epoch 467/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.2132 - mae: 0.8538 - val_loss: 1.1117 - val_mae: 0.8369\n",
            "Epoch 468/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1853 - mae: 0.8480 - val_loss: 1.3897 - val_mae: 0.9702\n",
            "Epoch 469/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1965 - mae: 0.8586 - val_loss: 1.1512 - val_mae: 0.8831\n",
            "Epoch 470/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.2441 - mae: 0.8644 - val_loss: 1.1290 - val_mae: 0.8712\n",
            "Epoch 471/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1474 - mae: 0.8413 - val_loss: 1.1526 - val_mae: 0.8353\n",
            "Epoch 472/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.2837 - mae: 0.8652 - val_loss: 1.4839 - val_mae: 1.0021\n",
            "Epoch 473/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1814 - mae: 0.8478 - val_loss: 1.3108 - val_mae: 0.8737\n",
            "Epoch 474/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1869 - mae: 0.8586 - val_loss: 1.2014 - val_mae: 0.9035\n",
            "Epoch 475/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1838 - mae: 0.8473 - val_loss: 1.2007 - val_mae: 0.8455\n",
            "Epoch 476/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.2383 - mae: 0.8628 - val_loss: 1.4771 - val_mae: 1.0004\n",
            "Epoch 477/1000\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 1.2248 - mae: 0.8672 - val_loss: 1.1927 - val_mae: 0.8437\n",
            "Epoch 478/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1675 - mae: 0.8463 - val_loss: 1.3313 - val_mae: 0.8790\n",
            "Epoch 479/1000\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 1.1831 - mae: 0.8583 - val_loss: 1.1109 - val_mae: 0.8342\n",
            "Epoch 480/1000\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 1.2165 - mae: 0.8497 - val_loss: 1.5794 - val_mae: 0.9576\n",
            "Epoch 481/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.2389 - mae: 0.8661 - val_loss: 1.1287 - val_mae: 0.8358\n",
            "Epoch 482/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1483 - mae: 0.8400 - val_loss: 1.1054 - val_mae: 0.8386\n",
            "Epoch 483/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.2067 - mae: 0.8579 - val_loss: 1.2372 - val_mae: 0.9125\n",
            "Epoch 484/1000\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 1.1443 - mae: 0.8333 - val_loss: 1.2721 - val_mae: 0.9305\n",
            "Epoch 485/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.2394 - mae: 0.8636 - val_loss: 1.3452 - val_mae: 0.9522\n",
            "Epoch 486/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.2184 - mae: 0.8696 - val_loss: 1.1356 - val_mae: 0.8731\n",
            "Epoch 487/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1595 - mae: 0.8480 - val_loss: 1.1802 - val_mae: 0.8412\n",
            "Epoch 488/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1433 - mae: 0.8364 - val_loss: 1.1150 - val_mae: 0.8422\n",
            "Epoch 489/1000\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 1.1552 - mae: 0.8490 - val_loss: 1.4537 - val_mae: 0.9929\n",
            "Epoch 490/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1867 - mae: 0.8493 - val_loss: 1.1068 - val_mae: 0.8410\n",
            "Epoch 491/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.2136 - mae: 0.8586 - val_loss: 1.3103 - val_mae: 0.8743\n",
            "Epoch 492/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.2006 - mae: 0.8592 - val_loss: 1.1471 - val_mae: 0.8798\n",
            "Epoch 493/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1563 - mae: 0.8395 - val_loss: 1.1646 - val_mae: 0.8879\n",
            "Epoch 494/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.2253 - mae: 0.8670 - val_loss: 1.1001 - val_mae: 0.8473\n",
            "Epoch 495/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1662 - mae: 0.8400 - val_loss: 1.1046 - val_mae: 0.8417\n",
            "Epoch 496/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1719 - mae: 0.8524 - val_loss: 1.1768 - val_mae: 0.8914\n",
            "Epoch 497/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1479 - mae: 0.8437 - val_loss: 1.4984 - val_mae: 1.0067\n",
            "Epoch 498/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1491 - mae: 0.8455 - val_loss: 1.1814 - val_mae: 0.8957\n",
            "Epoch 499/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.2212 - mae: 0.8612 - val_loss: 1.1476 - val_mae: 0.8350\n",
            "Epoch 500/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1661 - mae: 0.8511 - val_loss: 1.1468 - val_mae: 0.8794\n",
            "Epoch 501/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1701 - mae: 0.8448 - val_loss: 1.1237 - val_mae: 0.8346\n",
            "Epoch 502/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.2119 - mae: 0.8588 - val_loss: 1.1205 - val_mae: 0.8343\n",
            "Epoch 503/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1784 - mae: 0.8485 - val_loss: 1.1254 - val_mae: 0.8685\n",
            "Epoch 504/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1894 - mae: 0.8541 - val_loss: 1.1453 - val_mae: 0.8777\n",
            "Epoch 505/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.2187 - mae: 0.8657 - val_loss: 1.1584 - val_mae: 0.8379\n",
            "Epoch 506/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1622 - mae: 0.8476 - val_loss: 1.1443 - val_mae: 0.8770\n",
            "Epoch 507/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1696 - mae: 0.8577 - val_loss: 1.1012 - val_mae: 0.8500\n",
            "Epoch 508/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1808 - mae: 0.8569 - val_loss: 1.1027 - val_mae: 0.8377\n",
            "Epoch 509/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1755 - mae: 0.8436 - val_loss: 1.1646 - val_mae: 0.8855\n",
            "Epoch 510/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.2057 - mae: 0.8559 - val_loss: 1.2648 - val_mae: 0.9273\n",
            "Epoch 511/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1903 - mae: 0.8492 - val_loss: 1.3902 - val_mae: 0.9714\n",
            "Epoch 512/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1603 - mae: 0.8335 - val_loss: 1.4352 - val_mae: 0.9839\n",
            "Epoch 513/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1810 - mae: 0.8555 - val_loss: 1.1083 - val_mae: 0.8567\n",
            "Epoch 514/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1825 - mae: 0.8564 - val_loss: 1.2391 - val_mae: 0.9159\n",
            "Epoch 515/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1787 - mae: 0.8493 - val_loss: 1.1072 - val_mae: 0.8356\n",
            "Epoch 516/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1690 - mae: 0.8409 - val_loss: 1.1049 - val_mae: 0.8541\n",
            "Epoch 517/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1772 - mae: 0.8397 - val_loss: 1.1277 - val_mae: 0.8331\n",
            "Epoch 518/1000\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 1.1785 - mae: 0.8429 - val_loss: 1.1901 - val_mae: 0.8440\n",
            "Epoch 519/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1741 - mae: 0.8630 - val_loss: 1.1147 - val_mae: 0.8340\n",
            "Epoch 520/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1968 - mae: 0.8587 - val_loss: 1.3393 - val_mae: 0.8816\n",
            "Epoch 521/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1863 - mae: 0.8459 - val_loss: 1.1118 - val_mae: 0.8506\n",
            "Epoch 522/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1767 - mae: 0.8500 - val_loss: 1.5092 - val_mae: 0.9349\n",
            "Epoch 523/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1941 - mae: 0.8608 - val_loss: 1.1025 - val_mae: 0.8412\n",
            "Epoch 524/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.2111 - mae: 0.8503 - val_loss: 1.1012 - val_mae: 0.8496\n",
            "Epoch 525/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1697 - mae: 0.8566 - val_loss: 1.4286 - val_mae: 0.9840\n",
            "Epoch 526/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1522 - mae: 0.8389 - val_loss: 1.2200 - val_mae: 0.9080\n",
            "Epoch 527/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.2050 - mae: 0.8660 - val_loss: 1.3066 - val_mae: 0.9418\n",
            "Epoch 528/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1715 - mae: 0.8440 - val_loss: 1.3090 - val_mae: 0.8740\n",
            "Epoch 529/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1869 - mae: 0.8456 - val_loss: 1.1226 - val_mae: 0.8380\n",
            "Epoch 530/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.2272 - mae: 0.8646 - val_loss: 1.1112 - val_mae: 0.8597\n",
            "Epoch 531/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1837 - mae: 0.8558 - val_loss: 1.3001 - val_mae: 0.9387\n",
            "Epoch 532/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1697 - mae: 0.8449 - val_loss: 1.3782 - val_mae: 0.9678\n",
            "Epoch 533/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.2006 - mae: 0.8575 - val_loss: 1.2268 - val_mae: 0.9115\n",
            "Epoch 534/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1977 - mae: 0.8501 - val_loss: 1.2719 - val_mae: 0.9328\n",
            "Epoch 535/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1687 - mae: 0.8425 - val_loss: 1.1615 - val_mae: 0.8380\n",
            "Epoch 536/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1701 - mae: 0.8449 - val_loss: 1.4657 - val_mae: 0.9217\n",
            "Epoch 537/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1633 - mae: 0.8436 - val_loss: 1.9757 - val_mae: 1.1352\n",
            "Epoch 538/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1723 - mae: 0.8512 - val_loss: 1.1059 - val_mae: 0.8561\n",
            "Epoch 539/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1522 - mae: 0.8481 - val_loss: 1.2457 - val_mae: 0.9177\n",
            "Epoch 540/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1776 - mae: 0.8430 - val_loss: 1.1101 - val_mae: 0.8356\n",
            "Epoch 541/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1771 - mae: 0.8568 - val_loss: 1.0997 - val_mae: 0.8459\n",
            "Epoch 542/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.2204 - mae: 0.8540 - val_loss: 1.1340 - val_mae: 0.8735\n",
            "Epoch 543/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.2029 - mae: 0.8514 - val_loss: 1.4608 - val_mae: 0.9209\n",
            "Epoch 544/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1870 - mae: 0.8458 - val_loss: 1.8066 - val_mae: 1.0303\n",
            "Epoch 545/1000\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 1.2154 - mae: 0.8453 - val_loss: 1.2429 - val_mae: 0.8573\n",
            "Epoch 546/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1721 - mae: 0.8449 - val_loss: 1.4272 - val_mae: 0.9087\n",
            "Epoch 547/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1670 - mae: 0.8521 - val_loss: 1.6041 - val_mae: 1.0362\n",
            "Epoch 548/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.2222 - mae: 0.8522 - val_loss: 1.1353 - val_mae: 0.8753\n",
            "Epoch 549/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1813 - mae: 0.8586 - val_loss: 1.1078 - val_mae: 0.8355\n",
            "Epoch 550/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1744 - mae: 0.8523 - val_loss: 1.0993 - val_mae: 0.8427\n",
            "Epoch 551/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1526 - mae: 0.8362 - val_loss: 1.1930 - val_mae: 0.9013\n",
            "Epoch 552/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1784 - mae: 0.8495 - val_loss: 1.2202 - val_mae: 0.9108\n",
            "Epoch 553/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1449 - mae: 0.8369 - val_loss: 1.1824 - val_mae: 0.8430\n",
            "Epoch 554/1000\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 1.2290 - mae: 0.8599 - val_loss: 1.1545 - val_mae: 0.8377\n",
            "Epoch 555/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1891 - mae: 0.8533 - val_loss: 1.1157 - val_mae: 0.8638\n",
            "Epoch 556/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.2301 - mae: 0.8685 - val_loss: 1.3934 - val_mae: 0.9732\n",
            "Epoch 557/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.2120 - mae: 0.8684 - val_loss: 1.1488 - val_mae: 0.8364\n",
            "Epoch 558/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1707 - mae: 0.8410 - val_loss: 1.1051 - val_mae: 0.8362\n",
            "Epoch 559/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1698 - mae: 0.8576 - val_loss: 1.3124 - val_mae: 0.8745\n",
            "Epoch 560/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1658 - mae: 0.8544 - val_loss: 1.2165 - val_mae: 0.8506\n",
            "Epoch 561/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.2072 - mae: 0.8561 - val_loss: 1.2898 - val_mae: 0.8692\n",
            "Epoch 562/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.2023 - mae: 0.8636 - val_loss: 1.5794 - val_mae: 0.9589\n",
            "Epoch 563/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1839 - mae: 0.8547 - val_loss: 1.2494 - val_mae: 0.9262\n",
            "Epoch 564/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1934 - mae: 0.8579 - val_loss: 1.1436 - val_mae: 0.8789\n",
            "Epoch 565/1000\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 1.2126 - mae: 0.8687 - val_loss: 1.3639 - val_mae: 0.8890\n",
            "Epoch 566/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.2367 - mae: 0.8559 - val_loss: 1.4288 - val_mae: 0.9087\n",
            "Epoch 567/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1616 - mae: 0.8472 - val_loss: 1.1643 - val_mae: 0.8900\n",
            "Epoch 568/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1931 - mae: 0.8590 - val_loss: 1.1599 - val_mae: 0.8869\n",
            "Epoch 569/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1907 - mae: 0.8647 - val_loss: 1.2459 - val_mae: 0.9199\n",
            "Epoch 570/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1504 - mae: 0.8489 - val_loss: 1.1114 - val_mae: 0.8597\n",
            "Epoch 571/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1997 - mae: 0.8563 - val_loss: 1.1886 - val_mae: 0.8979\n",
            "Epoch 572/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.2137 - mae: 0.8644 - val_loss: 1.1787 - val_mae: 0.8418\n",
            "Epoch 573/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1745 - mae: 0.8502 - val_loss: 1.2096 - val_mae: 0.9053\n",
            "Epoch 574/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.2126 - mae: 0.8792 - val_loss: 1.1079 - val_mae: 0.8359\n",
            "Epoch 575/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1768 - mae: 0.8475 - val_loss: 1.2131 - val_mae: 0.8502\n",
            "Epoch 576/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1822 - mae: 0.8505 - val_loss: 1.2547 - val_mae: 0.9224\n",
            "Epoch 577/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.2055 - mae: 0.8621 - val_loss: 1.1835 - val_mae: 0.8434\n",
            "Epoch 578/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1616 - mae: 0.8443 - val_loss: 1.1016 - val_mae: 0.8420\n",
            "Epoch 579/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1987 - mae: 0.8552 - val_loss: 1.3016 - val_mae: 0.9397\n",
            "Epoch 580/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.2020 - mae: 0.8528 - val_loss: 1.3460 - val_mae: 0.9570\n",
            "Epoch 581/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1688 - mae: 0.8531 - val_loss: 1.3083 - val_mae: 0.9419\n",
            "Epoch 582/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1910 - mae: 0.8591 - val_loss: 1.1430 - val_mae: 0.8785\n",
            "Epoch 583/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1681 - mae: 0.8516 - val_loss: 1.2139 - val_mae: 0.9109\n",
            "Epoch 584/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.2224 - mae: 0.8558 - val_loss: 1.4093 - val_mae: 0.9028\n",
            "Epoch 585/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1588 - mae: 0.8366 - val_loss: 1.2639 - val_mae: 0.8625\n",
            "Epoch 586/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1666 - mae: 0.8484 - val_loss: 1.2391 - val_mae: 0.8565\n",
            "Epoch 587/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.2048 - mae: 0.8552 - val_loss: 1.3141 - val_mae: 0.9433\n",
            "Epoch 588/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1268 - mae: 0.8290 - val_loss: 1.0998 - val_mae: 0.8482\n",
            "Epoch 589/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.2026 - mae: 0.8597 - val_loss: 1.2893 - val_mae: 0.9351\n",
            "Epoch 590/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1781 - mae: 0.8500 - val_loss: 1.5250 - val_mae: 0.9404\n",
            "Epoch 591/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1566 - mae: 0.8466 - val_loss: 1.1660 - val_mae: 0.8898\n",
            "Epoch 592/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1793 - mae: 0.8559 - val_loss: 1.4966 - val_mae: 1.0042\n",
            "Epoch 593/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1630 - mae: 0.8472 - val_loss: 1.1710 - val_mae: 0.8914\n",
            "Epoch 594/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1612 - mae: 0.8466 - val_loss: 1.7425 - val_mae: 1.0708\n",
            "Epoch 595/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.2084 - mae: 0.8600 - val_loss: 1.1099 - val_mae: 0.8587\n",
            "Epoch 596/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1587 - mae: 0.8363 - val_loss: 1.3890 - val_mae: 0.9708\n",
            "Epoch 597/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.2290 - mae: 0.8673 - val_loss: 1.1821 - val_mae: 0.8960\n",
            "Epoch 598/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1585 - mae: 0.8400 - val_loss: 1.3513 - val_mae: 0.9587\n",
            "Epoch 599/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1165 - mae: 0.8470 - val_loss: 1.3365 - val_mae: 0.8820\n",
            "Epoch 600/1000\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 1.2127 - mae: 0.8580 - val_loss: 1.2968 - val_mae: 0.9399\n",
            "Epoch 601/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1780 - mae: 0.8517 - val_loss: 1.7360 - val_mae: 1.0105\n",
            "Epoch 602/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.2213 - mae: 0.8563 - val_loss: 1.2275 - val_mae: 0.8540\n",
            "Epoch 603/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1438 - mae: 0.8410 - val_loss: 1.2582 - val_mae: 0.8619\n",
            "Epoch 604/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1718 - mae: 0.8500 - val_loss: 1.1233 - val_mae: 0.8695\n",
            "Epoch 605/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1914 - mae: 0.8497 - val_loss: 1.1073 - val_mae: 0.8528\n",
            "Epoch 606/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1751 - mae: 0.8516 - val_loss: 1.2202 - val_mae: 0.8524\n",
            "Epoch 607/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.2078 - mae: 0.8562 - val_loss: 1.1031 - val_mae: 0.8540\n",
            "Epoch 608/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1623 - mae: 0.8402 - val_loss: 1.1432 - val_mae: 0.8793\n",
            "Epoch 609/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1630 - mae: 0.8452 - val_loss: 1.0992 - val_mae: 0.8489\n",
            "Epoch 610/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1681 - mae: 0.8392 - val_loss: 1.1808 - val_mae: 0.8433\n",
            "Epoch 611/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1961 - mae: 0.8503 - val_loss: 1.2286 - val_mae: 0.9131\n",
            "Epoch 612/1000\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 1.1557 - mae: 0.8431 - val_loss: 1.1390 - val_mae: 0.8773\n",
            "Epoch 613/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1527 - mae: 0.8563 - val_loss: 1.1333 - val_mae: 0.8752\n",
            "Epoch 614/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1421 - mae: 0.8418 - val_loss: 1.1017 - val_mae: 0.8431\n",
            "Epoch 615/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.2246 - mae: 0.8732 - val_loss: 1.1069 - val_mae: 0.8582\n",
            "Epoch 616/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1485 - mae: 0.8411 - val_loss: 1.7707 - val_mae: 1.0774\n",
            "Epoch 617/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.2356 - mae: 0.8682 - val_loss: 1.1263 - val_mae: 0.8351\n",
            "Epoch 618/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1515 - mae: 0.8386 - val_loss: 1.1195 - val_mae: 0.8387\n",
            "Epoch 619/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.2071 - mae: 0.8729 - val_loss: 1.1782 - val_mae: 0.8430\n",
            "Epoch 620/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1844 - mae: 0.8514 - val_loss: 1.2569 - val_mae: 0.8617\n",
            "Epoch 621/1000\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 1.1633 - mae: 0.8538 - val_loss: 1.0999 - val_mae: 0.8485\n",
            "Epoch 622/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1813 - mae: 0.8621 - val_loss: 1.2474 - val_mae: 0.8594\n",
            "Epoch 623/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1720 - mae: 0.8524 - val_loss: 1.5133 - val_mae: 0.9362\n",
            "Epoch 624/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1898 - mae: 0.8518 - val_loss: 1.1081 - val_mae: 0.8356\n",
            "Epoch 625/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1636 - mae: 0.8543 - val_loss: 1.4626 - val_mae: 0.9939\n",
            "Epoch 626/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1737 - mae: 0.8427 - val_loss: 1.1019 - val_mae: 0.8507\n",
            "Epoch 627/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1830 - mae: 0.8602 - val_loss: 1.4307 - val_mae: 0.9829\n",
            "Epoch 628/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1854 - mae: 0.8655 - val_loss: 1.1976 - val_mae: 0.8995\n",
            "Epoch 629/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1823 - mae: 0.8637 - val_loss: 1.1397 - val_mae: 0.8353\n",
            "Epoch 630/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.2114 - mae: 0.8661 - val_loss: 1.3068 - val_mae: 0.9408\n",
            "Epoch 631/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1961 - mae: 0.8443 - val_loss: 1.1151 - val_mae: 0.8368\n",
            "Epoch 632/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1793 - mae: 0.8527 - val_loss: 1.1545 - val_mae: 0.8842\n",
            "Epoch 633/1000\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 1.2034 - mae: 0.8627 - val_loss: 1.1283 - val_mae: 0.8351\n",
            "Epoch 634/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.2268 - mae: 0.8739 - val_loss: 1.1875 - val_mae: 0.8446\n",
            "Epoch 635/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1791 - mae: 0.8573 - val_loss: 1.0995 - val_mae: 0.8393\n",
            "Epoch 636/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1553 - mae: 0.8372 - val_loss: 1.1325 - val_mae: 0.8738\n",
            "Epoch 637/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.2695 - mae: 0.8712 - val_loss: 1.4711 - val_mae: 0.9236\n",
            "Epoch 638/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1957 - mae: 0.8515 - val_loss: 1.9103 - val_mae: 1.1137\n",
            "Epoch 639/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1743 - mae: 0.8518 - val_loss: 1.1303 - val_mae: 0.8721\n",
            "Epoch 640/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1589 - mae: 0.8443 - val_loss: 1.0981 - val_mae: 0.8458\n",
            "Epoch 641/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1543 - mae: 0.8408 - val_loss: 1.3578 - val_mae: 0.9560\n",
            "Epoch 642/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1841 - mae: 0.8637 - val_loss: 1.1345 - val_mae: 0.8748\n",
            "Epoch 643/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1389 - mae: 0.8427 - val_loss: 1.1311 - val_mae: 0.8346\n",
            "Epoch 644/1000\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 1.1184 - mae: 0.8276 - val_loss: 1.1223 - val_mae: 0.8347\n",
            "Epoch 645/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.2019 - mae: 0.8601 - val_loss: 1.1002 - val_mae: 0.8399\n",
            "Epoch 646/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1435 - mae: 0.8237 - val_loss: 1.4260 - val_mae: 0.9797\n",
            "Epoch 647/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1821 - mae: 0.8567 - val_loss: 1.0975 - val_mae: 0.8419\n",
            "Epoch 648/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1534 - mae: 0.8303 - val_loss: 1.1077 - val_mae: 0.8399\n",
            "Epoch 649/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1971 - mae: 0.8643 - val_loss: 1.2870 - val_mae: 0.9344\n",
            "Epoch 650/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1194 - mae: 0.8329 - val_loss: 1.3936 - val_mae: 0.9711\n",
            "Epoch 651/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1914 - mae: 0.8512 - val_loss: 1.1033 - val_mae: 0.8383\n",
            "Epoch 652/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1695 - mae: 0.8577 - val_loss: 1.1839 - val_mae: 0.8961\n",
            "Epoch 653/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.2082 - mae: 0.8581 - val_loss: 1.5107 - val_mae: 1.0075\n",
            "Epoch 654/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.2005 - mae: 0.8569 - val_loss: 1.1574 - val_mae: 0.8853\n",
            "Epoch 655/1000\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 1.1816 - mae: 0.8592 - val_loss: 1.1015 - val_mae: 0.8419\n",
            "Epoch 656/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1494 - mae: 0.8326 - val_loss: 1.1744 - val_mae: 0.8937\n",
            "Epoch 657/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.2338 - mae: 0.8665 - val_loss: 1.1133 - val_mae: 0.8358\n",
            "Epoch 658/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1828 - mae: 0.8587 - val_loss: 1.1483 - val_mae: 0.8368\n",
            "Epoch 659/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.2430 - mae: 0.8611 - val_loss: 1.3534 - val_mae: 0.9569\n",
            "Epoch 660/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1353 - mae: 0.8439 - val_loss: 1.1053 - val_mae: 0.8366\n",
            "Epoch 661/1000\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 1.1781 - mae: 0.8423 - val_loss: 1.1180 - val_mae: 0.8361\n",
            "Epoch 662/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1779 - mae: 0.8496 - val_loss: 1.2644 - val_mae: 0.9250\n",
            "Epoch 663/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1819 - mae: 0.8557 - val_loss: 1.1064 - val_mae: 0.8360\n",
            "Epoch 664/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1994 - mae: 0.8671 - val_loss: 1.1258 - val_mae: 0.8707\n",
            "Epoch 665/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1604 - mae: 0.8556 - val_loss: 1.3043 - val_mae: 0.9385\n",
            "Epoch 666/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1557 - mae: 0.8388 - val_loss: 1.1353 - val_mae: 0.8752\n",
            "Epoch 667/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1952 - mae: 0.8589 - val_loss: 1.1997 - val_mae: 0.9004\n",
            "Epoch 668/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1531 - mae: 0.8384 - val_loss: 1.1000 - val_mae: 0.8506\n",
            "Epoch 669/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1904 - mae: 0.8599 - val_loss: 1.1513 - val_mae: 0.8819\n",
            "Epoch 670/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1676 - mae: 0.8417 - val_loss: 1.5376 - val_mae: 1.0154\n",
            "Epoch 671/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1632 - mae: 0.8434 - val_loss: 1.6957 - val_mae: 0.9963\n",
            "Epoch 672/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1917 - mae: 0.8574 - val_loss: 1.2021 - val_mae: 0.9037\n",
            "Epoch 673/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1593 - mae: 0.8471 - val_loss: 1.3982 - val_mae: 0.9023\n",
            "Epoch 674/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1542 - mae: 0.8548 - val_loss: 1.1984 - val_mae: 0.9021\n",
            "Epoch 675/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1879 - mae: 0.8473 - val_loss: 1.1277 - val_mae: 0.8342\n",
            "Epoch 676/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1823 - mae: 0.8590 - val_loss: 1.1058 - val_mae: 0.8379\n",
            "Epoch 677/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1894 - mae: 0.8636 - val_loss: 1.2719 - val_mae: 0.9288\n",
            "Epoch 678/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1677 - mae: 0.8473 - val_loss: 1.9890 - val_mae: 1.0917\n",
            "Epoch 679/1000\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 1.1989 - mae: 0.8614 - val_loss: 1.1039 - val_mae: 0.8534\n",
            "Epoch 680/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1636 - mae: 0.8505 - val_loss: 1.2010 - val_mae: 0.8479\n",
            "Epoch 681/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.2182 - mae: 0.8663 - val_loss: 1.1188 - val_mae: 0.8668\n",
            "Epoch 682/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1798 - mae: 0.8584 - val_loss: 1.1126 - val_mae: 0.8363\n",
            "Epoch 683/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1785 - mae: 0.8539 - val_loss: 1.0983 - val_mae: 0.8409\n",
            "Epoch 684/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1466 - mae: 0.8375 - val_loss: 1.0987 - val_mae: 0.8480\n",
            "Epoch 685/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.2170 - mae: 0.8592 - val_loss: 1.0989 - val_mae: 0.8390\n",
            "Epoch 686/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1850 - mae: 0.8534 - val_loss: 1.1052 - val_mae: 0.8379\n",
            "Epoch 687/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1954 - mae: 0.8594 - val_loss: 1.1019 - val_mae: 0.8533\n",
            "Epoch 688/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1664 - mae: 0.8529 - val_loss: 1.0985 - val_mae: 0.8391\n",
            "Epoch 689/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1528 - mae: 0.8325 - val_loss: 1.4514 - val_mae: 0.9885\n",
            "Epoch 690/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.2178 - mae: 0.8651 - val_loss: 1.0987 - val_mae: 0.8482\n",
            "Epoch 691/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1602 - mae: 0.8540 - val_loss: 1.1048 - val_mae: 0.8356\n",
            "Epoch 692/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1557 - mae: 0.8362 - val_loss: 1.1337 - val_mae: 0.8348\n",
            "Epoch 693/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1893 - mae: 0.8582 - val_loss: 1.3965 - val_mae: 0.9011\n",
            "Epoch 694/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.2091 - mae: 0.8589 - val_loss: 1.1296 - val_mae: 0.8347\n",
            "Epoch 695/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1503 - mae: 0.8495 - val_loss: 1.2018 - val_mae: 0.9026\n",
            "Epoch 696/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1838 - mae: 0.8531 - val_loss: 1.1557 - val_mae: 0.8376\n",
            "Epoch 697/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1848 - mae: 0.8442 - val_loss: 1.2559 - val_mae: 0.9212\n",
            "Epoch 698/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1627 - mae: 0.8478 - val_loss: 1.1003 - val_mae: 0.8496\n",
            "Epoch 699/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1517 - mae: 0.8457 - val_loss: 1.1206 - val_mae: 0.8679\n",
            "Epoch 700/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1902 - mae: 0.8572 - val_loss: 1.1703 - val_mae: 0.8899\n",
            "Epoch 701/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1606 - mae: 0.8502 - val_loss: 1.1240 - val_mae: 0.8701\n",
            "Epoch 702/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1586 - mae: 0.8486 - val_loss: 1.1106 - val_mae: 0.8366\n",
            "Epoch 703/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1743 - mae: 0.8522 - val_loss: 1.3380 - val_mae: 0.8839\n",
            "Epoch 704/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1548 - mae: 0.8497 - val_loss: 1.1172 - val_mae: 0.8657\n",
            "Epoch 705/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.2018 - mae: 0.8616 - val_loss: 1.0990 - val_mae: 0.8479\n",
            "Epoch 706/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1794 - mae: 0.8504 - val_loss: 1.1735 - val_mae: 0.8901\n",
            "Epoch 707/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1660 - mae: 0.8385 - val_loss: 1.1526 - val_mae: 0.8827\n",
            "Epoch 708/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1569 - mae: 0.8420 - val_loss: 1.1671 - val_mae: 0.8410\n",
            "Epoch 709/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1754 - mae: 0.8529 - val_loss: 1.2633 - val_mae: 0.9253\n",
            "Epoch 710/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1836 - mae: 0.8524 - val_loss: 1.0990 - val_mae: 0.8475\n",
            "Epoch 711/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.2145 - mae: 0.8614 - val_loss: 1.2396 - val_mae: 0.9155\n",
            "Epoch 712/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1669 - mae: 0.8406 - val_loss: 1.1012 - val_mae: 0.8514\n",
            "Epoch 713/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1378 - mae: 0.8428 - val_loss: 1.2470 - val_mae: 0.8598\n",
            "Epoch 714/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1887 - mae: 0.8657 - val_loss: 1.0986 - val_mae: 0.8449\n",
            "Epoch 715/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1775 - mae: 0.8461 - val_loss: 1.3002 - val_mae: 0.9396\n",
            "Epoch 716/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.2060 - mae: 0.8457 - val_loss: 1.1347 - val_mae: 0.8753\n",
            "Epoch 717/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.2082 - mae: 0.8647 - val_loss: 1.2045 - val_mae: 0.9048\n",
            "Epoch 718/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1547 - mae: 0.8366 - val_loss: 1.2627 - val_mae: 0.8646\n",
            "Epoch 719/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.2032 - mae: 0.8566 - val_loss: 1.1812 - val_mae: 0.8444\n",
            "Epoch 720/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1974 - mae: 0.8568 - val_loss: 1.1211 - val_mae: 0.8683\n",
            "Epoch 721/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1487 - mae: 0.8458 - val_loss: 1.2104 - val_mae: 0.9054\n",
            "Epoch 722/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1735 - mae: 0.8525 - val_loss: 1.0995 - val_mae: 0.8494\n",
            "Epoch 723/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1550 - mae: 0.8438 - val_loss: 1.3070 - val_mae: 0.8763\n",
            "Epoch 724/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1935 - mae: 0.8416 - val_loss: 1.1503 - val_mae: 0.8377\n",
            "Epoch 725/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1745 - mae: 0.8467 - val_loss: 1.3511 - val_mae: 0.9575\n",
            "Epoch 726/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1635 - mae: 0.8365 - val_loss: 1.7666 - val_mae: 1.0798\n",
            "Epoch 727/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1782 - mae: 0.8406 - val_loss: 1.1034 - val_mae: 0.8529\n",
            "Epoch 728/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1714 - mae: 0.8462 - val_loss: 1.1121 - val_mae: 0.8354\n",
            "Epoch 729/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1688 - mae: 0.8587 - val_loss: 1.4299 - val_mae: 0.9814\n",
            "Epoch 730/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1597 - mae: 0.8404 - val_loss: 1.1002 - val_mae: 0.8401\n",
            "Epoch 731/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1609 - mae: 0.8506 - val_loss: 1.3517 - val_mae: 0.9557\n",
            "Epoch 732/1000\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 1.1694 - mae: 0.8396 - val_loss: 1.1139 - val_mae: 0.8632\n",
            "Epoch 733/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1809 - mae: 0.8544 - val_loss: 1.1280 - val_mae: 0.8718\n",
            "Epoch 734/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1715 - mae: 0.8376 - val_loss: 1.1356 - val_mae: 0.8359\n",
            "Epoch 735/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1813 - mae: 0.8488 - val_loss: 1.2213 - val_mae: 0.9092\n",
            "Epoch 736/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1576 - mae: 0.8487 - val_loss: 1.7807 - val_mae: 1.0264\n",
            "Epoch 737/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1735 - mae: 0.8429 - val_loss: 1.1647 - val_mae: 0.8887\n",
            "Epoch 738/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1770 - mae: 0.8510 - val_loss: 1.1013 - val_mae: 0.8454\n",
            "Epoch 739/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.2116 - mae: 0.8522 - val_loss: 1.3738 - val_mae: 0.9641\n",
            "Epoch 740/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1346 - mae: 0.8363 - val_loss: 1.1359 - val_mae: 0.8360\n",
            "Epoch 741/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1686 - mae: 0.8530 - val_loss: 1.1021 - val_mae: 0.8443\n",
            "Epoch 742/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1924 - mae: 0.8502 - val_loss: 1.1121 - val_mae: 0.8360\n",
            "Epoch 743/1000\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 1.1727 - mae: 0.8397 - val_loss: 1.9099 - val_mae: 1.0630\n",
            "Epoch 744/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1706 - mae: 0.8444 - val_loss: 1.8486 - val_mae: 1.0993\n",
            "Epoch 745/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1780 - mae: 0.8563 - val_loss: 1.1274 - val_mae: 0.8356\n",
            "Epoch 746/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1746 - mae: 0.8458 - val_loss: 1.1433 - val_mae: 0.8391\n",
            "Epoch 747/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1965 - mae: 0.8474 - val_loss: 1.1006 - val_mae: 0.8503\n",
            "Epoch 748/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1814 - mae: 0.8608 - val_loss: 1.2299 - val_mae: 0.9121\n",
            "Epoch 749/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1346 - mae: 0.8383 - val_loss: 1.1804 - val_mae: 0.8944\n",
            "Epoch 750/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1965 - mae: 0.8493 - val_loss: 1.1570 - val_mae: 0.8386\n",
            "Epoch 751/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.2073 - mae: 0.8500 - val_loss: 1.6209 - val_mae: 0.9739\n",
            "Epoch 752/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1838 - mae: 0.8548 - val_loss: 1.7477 - val_mae: 1.0729\n",
            "Epoch 753/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1530 - mae: 0.8474 - val_loss: 1.1497 - val_mae: 0.8371\n",
            "Epoch 754/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.2217 - mae: 0.8620 - val_loss: 1.1090 - val_mae: 0.8358\n",
            "Epoch 755/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1792 - mae: 0.8431 - val_loss: 1.9633 - val_mae: 1.1296\n",
            "Epoch 756/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1704 - mae: 0.8609 - val_loss: 1.0996 - val_mae: 0.8454\n",
            "Epoch 757/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1491 - mae: 0.8402 - val_loss: 1.1064 - val_mae: 0.8560\n",
            "Epoch 758/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1422 - mae: 0.8398 - val_loss: 1.0998 - val_mae: 0.8398\n",
            "Epoch 759/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1810 - mae: 0.8503 - val_loss: 1.1082 - val_mae: 0.8580\n",
            "Epoch 760/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1851 - mae: 0.8526 - val_loss: 1.1403 - val_mae: 0.8775\n",
            "Epoch 761/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.2276 - mae: 0.8664 - val_loss: 1.1532 - val_mae: 0.8831\n",
            "Epoch 762/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1641 - mae: 0.8424 - val_loss: 1.1148 - val_mae: 0.8353\n",
            "Epoch 763/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1222 - mae: 0.8288 - val_loss: 1.1665 - val_mae: 0.8882\n",
            "Epoch 764/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1373 - mae: 0.8344 - val_loss: 1.6442 - val_mae: 0.9801\n",
            "Epoch 765/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1753 - mae: 0.8509 - val_loss: 1.1298 - val_mae: 0.8370\n",
            "Epoch 766/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1813 - mae: 0.8587 - val_loss: 1.1058 - val_mae: 0.8371\n",
            "Epoch 767/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1630 - mae: 0.8443 - val_loss: 1.1214 - val_mae: 0.8367\n",
            "Epoch 768/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1449 - mae: 0.8446 - val_loss: 1.2254 - val_mae: 0.8548\n",
            "Epoch 769/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1564 - mae: 0.8467 - val_loss: 1.1280 - val_mae: 0.8712\n",
            "Epoch 770/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1909 - mae: 0.8593 - val_loss: 1.1467 - val_mae: 0.8770\n",
            "Epoch 771/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1742 - mae: 0.8482 - val_loss: 1.2309 - val_mae: 0.8563\n",
            "Epoch 772/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1687 - mae: 0.8467 - val_loss: 1.3258 - val_mae: 0.9463\n",
            "Epoch 773/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1403 - mae: 0.8406 - val_loss: 1.7581 - val_mae: 1.0759\n",
            "Epoch 774/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1948 - mae: 0.8592 - val_loss: 1.1970 - val_mae: 0.8991\n",
            "Epoch 775/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1906 - mae: 0.8581 - val_loss: 1.1413 - val_mae: 0.8778\n",
            "Epoch 776/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1297 - mae: 0.8353 - val_loss: 1.2123 - val_mae: 0.8515\n",
            "Epoch 777/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1626 - mae: 0.8471 - val_loss: 1.2722 - val_mae: 0.9272\n",
            "Epoch 778/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1770 - mae: 0.8531 - val_loss: 1.1994 - val_mae: 0.9030\n",
            "Epoch 779/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1654 - mae: 0.8466 - val_loss: 1.1258 - val_mae: 0.8699\n",
            "Epoch 780/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1994 - mae: 0.8645 - val_loss: 1.2210 - val_mae: 0.9088\n",
            "Epoch 781/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1767 - mae: 0.8626 - val_loss: 1.1020 - val_mae: 0.8515\n",
            "Epoch 782/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1427 - mae: 0.8403 - val_loss: 1.1246 - val_mae: 0.8357\n",
            "Epoch 783/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1730 - mae: 0.8549 - val_loss: 1.4688 - val_mae: 0.9947\n",
            "Epoch 784/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1798 - mae: 0.8600 - val_loss: 1.1179 - val_mae: 0.8646\n",
            "Epoch 785/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1995 - mae: 0.8645 - val_loss: 1.1759 - val_mae: 0.8930\n",
            "Epoch 786/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1440 - mae: 0.8375 - val_loss: 1.2609 - val_mae: 0.8646\n",
            "Epoch 787/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1557 - mae: 0.8597 - val_loss: 1.1256 - val_mae: 0.8702\n",
            "Epoch 788/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1731 - mae: 0.8616 - val_loss: 1.1422 - val_mae: 0.8789\n",
            "Epoch 789/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1838 - mae: 0.8549 - val_loss: 1.1487 - val_mae: 0.8381\n",
            "Epoch 790/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1450 - mae: 0.8426 - val_loss: 1.1372 - val_mae: 0.8371\n",
            "Epoch 791/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.2048 - mae: 0.8597 - val_loss: 1.1421 - val_mae: 0.8384\n",
            "Epoch 792/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1399 - mae: 0.8389 - val_loss: 1.2421 - val_mae: 0.9172\n",
            "Epoch 793/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1958 - mae: 0.8631 - val_loss: 1.1103 - val_mae: 0.8376\n",
            "Epoch 794/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1697 - mae: 0.8429 - val_loss: 1.1463 - val_mae: 0.8373\n",
            "Epoch 795/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1679 - mae: 0.8486 - val_loss: 1.2670 - val_mae: 0.8670\n",
            "Epoch 796/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1740 - mae: 0.8499 - val_loss: 1.1364 - val_mae: 0.8762\n",
            "Epoch 797/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1745 - mae: 0.8465 - val_loss: 1.4405 - val_mae: 0.9857\n",
            "Epoch 798/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1675 - mae: 0.8393 - val_loss: 1.1591 - val_mae: 0.8842\n",
            "Epoch 799/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1644 - mae: 0.8494 - val_loss: 1.1361 - val_mae: 0.8367\n",
            "Epoch 800/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1972 - mae: 0.8643 - val_loss: 1.1941 - val_mae: 0.8480\n",
            "Epoch 801/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1323 - mae: 0.8359 - val_loss: 1.3339 - val_mae: 0.8847\n",
            "Epoch 802/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1809 - mae: 0.8552 - val_loss: 1.1359 - val_mae: 0.8733\n",
            "Epoch 803/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1653 - mae: 0.8415 - val_loss: 1.3766 - val_mae: 0.9650\n",
            "Epoch 804/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1839 - mae: 0.8522 - val_loss: 1.1028 - val_mae: 0.8502\n",
            "Epoch 805/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1380 - mae: 0.8450 - val_loss: 1.1075 - val_mae: 0.8385\n",
            "Epoch 806/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1794 - mae: 0.8651 - val_loss: 1.2756 - val_mae: 0.9302\n",
            "Epoch 807/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1857 - mae: 0.8483 - val_loss: 1.1850 - val_mae: 0.8457\n",
            "Epoch 808/1000\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 1.1693 - mae: 0.8494 - val_loss: 1.1854 - val_mae: 0.8455\n",
            "Epoch 809/1000\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 1.1485 - mae: 0.8462 - val_loss: 1.1358 - val_mae: 0.8756\n",
            "Epoch 810/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1791 - mae: 0.8483 - val_loss: 1.1321 - val_mae: 0.8365\n",
            "Epoch 811/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1609 - mae: 0.8397 - val_loss: 1.1032 - val_mae: 0.8399\n",
            "Epoch 812/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1557 - mae: 0.8320 - val_loss: 1.1518 - val_mae: 0.8824\n",
            "Epoch 813/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1607 - mae: 0.8456 - val_loss: 1.1085 - val_mae: 0.8378\n",
            "Epoch 814/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1470 - mae: 0.8354 - val_loss: 1.1366 - val_mae: 0.8749\n",
            "Epoch 815/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1864 - mae: 0.8450 - val_loss: 1.1523 - val_mae: 0.8382\n",
            "Epoch 816/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.2369 - mae: 0.8567 - val_loss: 1.1993 - val_mae: 0.9009\n",
            "Epoch 817/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1422 - mae: 0.8334 - val_loss: 1.1133 - val_mae: 0.8609\n",
            "Epoch 818/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1639 - mae: 0.8480 - val_loss: 1.2258 - val_mae: 0.8562\n",
            "Epoch 819/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1612 - mae: 0.8395 - val_loss: 1.1469 - val_mae: 0.8799\n",
            "Epoch 820/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1777 - mae: 0.8390 - val_loss: 1.4008 - val_mae: 0.9699\n",
            "Epoch 821/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.2050 - mae: 0.8598 - val_loss: 1.2948 - val_mae: 0.9352\n",
            "Epoch 822/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1012 - mae: 0.8320 - val_loss: 1.2228 - val_mae: 0.8553\n",
            "Epoch 823/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1868 - mae: 0.8565 - val_loss: 1.3042 - val_mae: 0.9407\n",
            "Epoch 824/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1537 - mae: 0.8425 - val_loss: 1.1274 - val_mae: 0.8367\n",
            "Epoch 825/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1808 - mae: 0.8541 - val_loss: 1.5126 - val_mae: 0.9409\n",
            "Epoch 826/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1274 - mae: 0.8368 - val_loss: 1.5676 - val_mae: 0.9582\n",
            "Epoch 827/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1722 - mae: 0.8510 - val_loss: 1.1297 - val_mae: 0.8371\n",
            "Epoch 828/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.2161 - mae: 0.8649 - val_loss: 1.1182 - val_mae: 0.8643\n",
            "Epoch 829/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1826 - mae: 0.8487 - val_loss: 1.1065 - val_mae: 0.8399\n",
            "Epoch 830/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1926 - mae: 0.8453 - val_loss: 1.3916 - val_mae: 0.9692\n",
            "Epoch 831/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1817 - mae: 0.8565 - val_loss: 1.1353 - val_mae: 0.8367\n",
            "Epoch 832/1000\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 1.2286 - mae: 0.8603 - val_loss: 1.6020 - val_mae: 1.0325\n",
            "Epoch 833/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1937 - mae: 0.8488 - val_loss: 1.2135 - val_mae: 0.9058\n",
            "Epoch 834/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1608 - mae: 0.8559 - val_loss: 1.1558 - val_mae: 0.8843\n",
            "Epoch 835/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1587 - mae: 0.8476 - val_loss: 1.1021 - val_mae: 0.8455\n",
            "Epoch 836/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1481 - mae: 0.8396 - val_loss: 1.1565 - val_mae: 0.8848\n",
            "Epoch 837/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.2121 - mae: 0.8656 - val_loss: 1.1101 - val_mae: 0.8449\n",
            "Epoch 838/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1778 - mae: 0.8452 - val_loss: 1.4170 - val_mae: 0.9764\n",
            "Epoch 839/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1404 - mae: 0.8480 - val_loss: 1.1029 - val_mae: 0.8436\n",
            "Epoch 840/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1633 - mae: 0.8447 - val_loss: 1.4273 - val_mae: 0.9134\n",
            "Epoch 841/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1859 - mae: 0.8645 - val_loss: 1.1418 - val_mae: 0.8783\n",
            "Epoch 842/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1870 - mae: 0.8462 - val_loss: 1.1563 - val_mae: 0.8397\n",
            "Epoch 843/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1634 - mae: 0.8511 - val_loss: 1.1789 - val_mae: 0.8461\n",
            "Epoch 844/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1613 - mae: 0.8400 - val_loss: 1.1819 - val_mae: 0.8946\n",
            "Epoch 845/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1481 - mae: 0.8487 - val_loss: 1.7046 - val_mae: 1.0046\n",
            "Epoch 846/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.2087 - mae: 0.8611 - val_loss: 1.1996 - val_mae: 0.8510\n",
            "Epoch 847/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1903 - mae: 0.8554 - val_loss: 1.1079 - val_mae: 0.8429\n",
            "Epoch 848/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.2028 - mae: 0.8619 - val_loss: 1.1212 - val_mae: 0.8392\n",
            "Epoch 849/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1293 - mae: 0.8385 - val_loss: 1.8384 - val_mae: 1.0942\n",
            "Epoch 850/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1830 - mae: 0.8597 - val_loss: 1.6329 - val_mae: 1.0393\n",
            "Epoch 851/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1885 - mae: 0.8568 - val_loss: 1.4543 - val_mae: 0.9898\n",
            "Epoch 852/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1599 - mae: 0.8578 - val_loss: 1.1130 - val_mae: 0.8606\n",
            "Epoch 853/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.2047 - mae: 0.8564 - val_loss: 1.3111 - val_mae: 0.9403\n",
            "Epoch 854/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1752 - mae: 0.8501 - val_loss: 1.3771 - val_mae: 0.9646\n",
            "Epoch 855/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1912 - mae: 0.8566 - val_loss: 1.2302 - val_mae: 0.8588\n",
            "Epoch 856/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1919 - mae: 0.8578 - val_loss: 1.1550 - val_mae: 0.8844\n",
            "Epoch 857/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1275 - mae: 0.8388 - val_loss: 1.1964 - val_mae: 0.9014\n",
            "Epoch 858/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1920 - mae: 0.8623 - val_loss: 1.2759 - val_mae: 0.8712\n",
            "Epoch 859/1000\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 1.1603 - mae: 0.8415 - val_loss: 1.1150 - val_mae: 0.8623\n",
            "Epoch 860/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1613 - mae: 0.8581 - val_loss: 1.6183 - val_mae: 1.0397\n",
            "Epoch 861/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1600 - mae: 0.8534 - val_loss: 1.1386 - val_mae: 0.8402\n",
            "Epoch 862/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1686 - mae: 0.8531 - val_loss: 1.2513 - val_mae: 0.9215\n",
            "Epoch 863/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1315 - mae: 0.8385 - val_loss: 1.1944 - val_mae: 0.8509\n",
            "Epoch 864/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1442 - mae: 0.8386 - val_loss: 1.1089 - val_mae: 0.8421\n",
            "Epoch 865/1000\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 1.1828 - mae: 0.8592 - val_loss: 1.3581 - val_mae: 0.8927\n",
            "Epoch 866/1000\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 1.1766 - mae: 0.8489 - val_loss: 1.1668 - val_mae: 0.8893\n",
            "Epoch 867/1000\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 1.1536 - mae: 0.8467 - val_loss: 1.4059 - val_mae: 0.9743\n",
            "Epoch 868/1000\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 1.1658 - mae: 0.8522 - val_loss: 1.1057 - val_mae: 0.8442\n",
            "Epoch 869/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.2000 - mae: 0.8598 - val_loss: 1.3523 - val_mae: 0.9561\n",
            "Epoch 870/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1677 - mae: 0.8544 - val_loss: 1.1298 - val_mae: 0.8730\n",
            "Epoch 871/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1466 - mae: 0.8460 - val_loss: 1.2557 - val_mae: 0.9207\n",
            "Epoch 872/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1726 - mae: 0.8434 - val_loss: 1.2451 - val_mae: 0.9179\n",
            "Epoch 873/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1691 - mae: 0.8492 - val_loss: 1.1277 - val_mae: 0.8389\n",
            "Epoch 874/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1753 - mae: 0.8536 - val_loss: 1.2820 - val_mae: 0.9333\n",
            "Epoch 875/1000\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 1.2086 - mae: 0.8688 - val_loss: 1.1145 - val_mae: 0.8401\n",
            "Epoch 876/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1928 - mae: 0.8528 - val_loss: 1.1676 - val_mae: 0.8440\n",
            "Epoch 877/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1555 - mae: 0.8460 - val_loss: 1.2227 - val_mae: 0.8567\n",
            "Epoch 878/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1891 - mae: 0.8530 - val_loss: 1.1068 - val_mae: 0.8545\n",
            "Epoch 879/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1687 - mae: 0.8486 - val_loss: 1.2206 - val_mae: 0.9097\n",
            "Epoch 880/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1393 - mae: 0.8442 - val_loss: 1.1077 - val_mae: 0.8440\n",
            "Epoch 881/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1744 - mae: 0.8545 - val_loss: 1.2550 - val_mae: 0.9218\n",
            "Epoch 882/1000\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 1.2084 - mae: 0.8542 - val_loss: 1.1835 - val_mae: 0.8965\n",
            "Epoch 883/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1854 - mae: 0.8645 - val_loss: 1.1909 - val_mae: 0.8500\n",
            "Epoch 884/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1711 - mae: 0.8571 - val_loss: 1.1301 - val_mae: 0.8400\n",
            "Epoch 885/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1945 - mae: 0.8595 - val_loss: 1.3398 - val_mae: 0.8882\n",
            "Epoch 886/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1952 - mae: 0.8576 - val_loss: 1.8887 - val_mae: 1.1104\n",
            "Epoch 887/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1947 - mae: 0.8660 - val_loss: 1.1787 - val_mae: 0.8937\n",
            "Epoch 888/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1803 - mae: 0.8551 - val_loss: 1.2117 - val_mae: 0.9067\n",
            "Epoch 889/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1157 - mae: 0.8258 - val_loss: 1.5358 - val_mae: 1.0166\n",
            "Epoch 890/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1870 - mae: 0.8551 - val_loss: 1.1631 - val_mae: 0.8880\n",
            "Epoch 891/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.2453 - mae: 0.8699 - val_loss: 1.4372 - val_mae: 0.9177\n",
            "Epoch 892/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1818 - mae: 0.8684 - val_loss: 1.1140 - val_mae: 0.8619\n",
            "Epoch 893/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1762 - mae: 0.8445 - val_loss: 1.3439 - val_mae: 0.9542\n",
            "Epoch 894/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1807 - mae: 0.8561 - val_loss: 1.1328 - val_mae: 0.8741\n",
            "Epoch 895/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1412 - mae: 0.8414 - val_loss: 1.1585 - val_mae: 0.8417\n",
            "Epoch 896/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1498 - mae: 0.8437 - val_loss: 1.1111 - val_mae: 0.8424\n",
            "Epoch 897/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1403 - mae: 0.8434 - val_loss: 1.1085 - val_mae: 0.8564\n",
            "Epoch 898/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1957 - mae: 0.8551 - val_loss: 1.1227 - val_mae: 0.8680\n",
            "Epoch 899/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1841 - mae: 0.8413 - val_loss: 1.1816 - val_mae: 0.8945\n",
            "Epoch 900/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1279 - mae: 0.8339 - val_loss: 1.1083 - val_mae: 0.8437\n",
            "Epoch 901/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1793 - mae: 0.8471 - val_loss: 1.1083 - val_mae: 0.8562\n",
            "Epoch 902/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1904 - mae: 0.8496 - val_loss: 1.3811 - val_mae: 0.9665\n",
            "Epoch 903/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1953 - mae: 0.8680 - val_loss: 1.1323 - val_mae: 0.8735\n",
            "Epoch 904/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1852 - mae: 0.8551 - val_loss: 1.1091 - val_mae: 0.8562\n",
            "Epoch 905/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1400 - mae: 0.8325 - val_loss: 1.1467 - val_mae: 0.8399\n",
            "Epoch 906/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1868 - mae: 0.8553 - val_loss: 1.1685 - val_mae: 0.8897\n",
            "Epoch 907/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1434 - mae: 0.8392 - val_loss: 1.2056 - val_mae: 0.9036\n",
            "Epoch 908/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1706 - mae: 0.8551 - val_loss: 1.1134 - val_mae: 0.8602\n",
            "Epoch 909/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1687 - mae: 0.8532 - val_loss: 1.1491 - val_mae: 0.8413\n",
            "Epoch 910/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1864 - mae: 0.8572 - val_loss: 1.2014 - val_mae: 0.9031\n",
            "Epoch 911/1000\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 1.1598 - mae: 0.8426 - val_loss: 1.1410 - val_mae: 0.8395\n",
            "Epoch 912/1000\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 1.1719 - mae: 0.8508 - val_loss: 1.3049 - val_mae: 0.9404\n",
            "Epoch 913/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1195 - mae: 0.8261 - val_loss: 1.1551 - val_mae: 0.8850\n",
            "Epoch 914/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1812 - mae: 0.8616 - val_loss: 1.2882 - val_mae: 0.8740\n",
            "Epoch 915/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1642 - mae: 0.8481 - val_loss: 1.1154 - val_mae: 0.8433\n",
            "Epoch 916/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1683 - mae: 0.8494 - val_loss: 1.5077 - val_mae: 1.0094\n",
            "Epoch 917/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1929 - mae: 0.8658 - val_loss: 1.2289 - val_mae: 0.8582\n",
            "Epoch 918/1000\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 1.1612 - mae: 0.8440 - val_loss: 1.1102 - val_mae: 0.8448\n",
            "Epoch 919/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1705 - mae: 0.8529 - val_loss: 1.2693 - val_mae: 0.9276\n",
            "Epoch 920/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1548 - mae: 0.8377 - val_loss: 1.5040 - val_mae: 1.0065\n",
            "Epoch 921/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.2197 - mae: 0.8625 - val_loss: 1.7293 - val_mae: 1.0116\n",
            "Epoch 922/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.2235 - mae: 0.8608 - val_loss: 1.1222 - val_mae: 0.8661\n",
            "Epoch 923/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1444 - mae: 0.8491 - val_loss: 1.1122 - val_mae: 0.8598\n",
            "Epoch 924/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1879 - mae: 0.8524 - val_loss: 1.1863 - val_mae: 0.8486\n",
            "Epoch 925/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1546 - mae: 0.8410 - val_loss: 1.5126 - val_mae: 1.0077\n",
            "Epoch 926/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1990 - mae: 0.8738 - val_loss: 1.3500 - val_mae: 0.9573\n",
            "Epoch 927/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1948 - mae: 0.8452 - val_loss: 1.2605 - val_mae: 0.8670\n",
            "Epoch 928/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1243 - mae: 0.8293 - val_loss: 1.4697 - val_mae: 0.9269\n",
            "Epoch 929/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1510 - mae: 0.8492 - val_loss: 1.3882 - val_mae: 0.9013\n",
            "Epoch 930/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1602 - mae: 0.8548 - val_loss: 1.1270 - val_mae: 0.8398\n",
            "Epoch 931/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.2114 - mae: 0.8634 - val_loss: 1.1379 - val_mae: 0.8770\n",
            "Epoch 932/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1956 - mae: 0.8507 - val_loss: 1.1171 - val_mae: 0.8410\n",
            "Epoch 933/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1704 - mae: 0.8488 - val_loss: 1.1169 - val_mae: 0.8407\n",
            "Epoch 934/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.2003 - mae: 0.8575 - val_loss: 1.1736 - val_mae: 0.8459\n",
            "Epoch 935/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1639 - mae: 0.8524 - val_loss: 1.3920 - val_mae: 0.9716\n",
            "Epoch 936/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1264 - mae: 0.8401 - val_loss: 1.1204 - val_mae: 0.8402\n",
            "Epoch 937/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1767 - mae: 0.8432 - val_loss: 1.6520 - val_mae: 0.9869\n",
            "Epoch 938/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1540 - mae: 0.8473 - val_loss: 1.2020 - val_mae: 0.8528\n",
            "Epoch 939/1000\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 1.1555 - mae: 0.8443 - val_loss: 1.1343 - val_mae: 0.8407\n",
            "Epoch 940/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.2302 - mae: 0.8656 - val_loss: 1.1312 - val_mae: 0.8727\n",
            "Epoch 941/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1259 - mae: 0.8316 - val_loss: 1.1959 - val_mae: 0.9006\n",
            "Epoch 942/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1524 - mae: 0.8435 - val_loss: 1.1358 - val_mae: 0.8407\n",
            "Epoch 943/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1103 - mae: 0.8364 - val_loss: 1.2798 - val_mae: 0.9300\n",
            "Epoch 944/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1416 - mae: 0.8380 - val_loss: 1.1118 - val_mae: 0.8410\n",
            "Epoch 945/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1908 - mae: 0.8501 - val_loss: 1.1437 - val_mae: 0.8785\n",
            "Epoch 946/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1451 - mae: 0.8417 - val_loss: 1.1074 - val_mae: 0.8484\n",
            "Epoch 947/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.2144 - mae: 0.8590 - val_loss: 1.1761 - val_mae: 0.8927\n",
            "Epoch 948/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1243 - mae: 0.8256 - val_loss: 1.6011 - val_mae: 0.9719\n",
            "Epoch 949/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1872 - mae: 0.8530 - val_loss: 1.7389 - val_mae: 1.0701\n",
            "Epoch 950/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1737 - mae: 0.8541 - val_loss: 1.1173 - val_mae: 0.8405\n",
            "Epoch 951/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1683 - mae: 0.8527 - val_loss: 1.1124 - val_mae: 0.8413\n",
            "Epoch 952/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1004 - mae: 0.8253 - val_loss: 1.1571 - val_mae: 0.8848\n",
            "Epoch 953/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1900 - mae: 0.8468 - val_loss: 1.2098 - val_mae: 0.9061\n",
            "Epoch 954/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1690 - mae: 0.8482 - val_loss: 1.4958 - val_mae: 0.9355\n",
            "Epoch 955/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.2098 - mae: 0.8576 - val_loss: 1.5296 - val_mae: 1.0135\n",
            "Epoch 956/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1337 - mae: 0.8325 - val_loss: 1.1101 - val_mae: 0.8550\n",
            "Epoch 957/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1339 - mae: 0.8385 - val_loss: 1.1400 - val_mae: 0.8778\n",
            "Epoch 958/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1939 - mae: 0.8566 - val_loss: 1.2132 - val_mae: 0.9069\n",
            "Epoch 959/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1871 - mae: 0.8508 - val_loss: 1.1532 - val_mae: 0.8836\n",
            "Epoch 960/1000\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 1.1349 - mae: 0.8446 - val_loss: 1.1721 - val_mae: 0.8457\n",
            "Epoch 961/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1396 - mae: 0.8490 - val_loss: 1.1095 - val_mae: 0.8433\n",
            "Epoch 962/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1713 - mae: 0.8509 - val_loss: 1.7899 - val_mae: 1.0831\n",
            "Epoch 963/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1514 - mae: 0.8403 - val_loss: 1.1599 - val_mae: 0.8433\n",
            "Epoch 964/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1333 - mae: 0.8330 - val_loss: 1.2772 - val_mae: 0.8717\n",
            "Epoch 965/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1613 - mae: 0.8540 - val_loss: 1.1187 - val_mae: 0.8643\n",
            "Epoch 966/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1284 - mae: 0.8443 - val_loss: 1.2307 - val_mae: 0.9141\n",
            "Epoch 967/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.2409 - mae: 0.8605 - val_loss: 1.1419 - val_mae: 0.8788\n",
            "Epoch 968/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1761 - mae: 0.8458 - val_loss: 1.1119 - val_mae: 0.8562\n",
            "Epoch 969/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1213 - mae: 0.8363 - val_loss: 1.3695 - val_mae: 0.9629\n",
            "Epoch 970/1000\n",
            "38/38 [==============================] - 0s 7ms/step - loss: 1.2324 - mae: 0.8617 - val_loss: 1.4394 - val_mae: 0.9178\n",
            "Epoch 971/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1705 - mae: 0.8409 - val_loss: 1.2360 - val_mae: 0.9172\n",
            "Epoch 972/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1163 - mae: 0.8308 - val_loss: 1.1351 - val_mae: 0.8400\n",
            "Epoch 973/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.2008 - mae: 0.8693 - val_loss: 1.2292 - val_mae: 0.8590\n",
            "Epoch 974/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1633 - mae: 0.8531 - val_loss: 1.1681 - val_mae: 0.8434\n",
            "Epoch 975/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1757 - mae: 0.8543 - val_loss: 1.1148 - val_mae: 0.8404\n",
            "Epoch 976/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1470 - mae: 0.8498 - val_loss: 1.1114 - val_mae: 0.8572\n",
            "Epoch 977/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1556 - mae: 0.8389 - val_loss: 1.6706 - val_mae: 1.0521\n",
            "Epoch 978/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1676 - mae: 0.8490 - val_loss: 1.3469 - val_mae: 0.8904\n",
            "Epoch 979/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1579 - mae: 0.8408 - val_loss: 1.6265 - val_mae: 0.9798\n",
            "Epoch 980/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1796 - mae: 0.8568 - val_loss: 1.1099 - val_mae: 0.8564\n",
            "Epoch 981/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1627 - mae: 0.8458 - val_loss: 1.2771 - val_mae: 0.9289\n",
            "Epoch 982/1000\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 1.1527 - mae: 0.8422 - val_loss: 1.1468 - val_mae: 0.8412\n",
            "Epoch 983/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1885 - mae: 0.8596 - val_loss: 1.1853 - val_mae: 0.8477\n",
            "Epoch 984/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1953 - mae: 0.8613 - val_loss: 1.1383 - val_mae: 0.8396\n",
            "Epoch 985/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1861 - mae: 0.8552 - val_loss: 1.3101 - val_mae: 0.8802\n",
            "Epoch 986/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1460 - mae: 0.8415 - val_loss: 1.2426 - val_mae: 0.9169\n",
            "Epoch 987/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1504 - mae: 0.8487 - val_loss: 1.1824 - val_mae: 0.8475\n",
            "Epoch 988/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1745 - mae: 0.8520 - val_loss: 1.1131 - val_mae: 0.8551\n",
            "Epoch 989/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1817 - mae: 0.8468 - val_loss: 1.1586 - val_mae: 0.8430\n",
            "Epoch 990/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1410 - mae: 0.8461 - val_loss: 1.2411 - val_mae: 0.9173\n",
            "Epoch 991/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.2068 - mae: 0.8695 - val_loss: 1.2614 - val_mae: 0.8677\n",
            "Epoch 992/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1816 - mae: 0.8547 - val_loss: 1.2101 - val_mae: 0.8537\n",
            "Epoch 993/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1467 - mae: 0.8471 - val_loss: 1.1746 - val_mae: 0.8455\n",
            "Epoch 994/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1922 - mae: 0.8535 - val_loss: 1.3710 - val_mae: 0.9631\n",
            "Epoch 995/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1694 - mae: 0.8530 - val_loss: 1.6346 - val_mae: 0.9814\n",
            "Epoch 996/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1076 - mae: 0.8288 - val_loss: 1.1745 - val_mae: 0.8924\n",
            "Epoch 997/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1379 - mae: 0.8542 - val_loss: 1.2688 - val_mae: 0.8696\n",
            "Epoch 998/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1910 - mae: 0.8462 - val_loss: 1.1520 - val_mae: 0.8412\n",
            "Epoch 999/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1634 - mae: 0.8447 - val_loss: 1.3598 - val_mae: 0.9590\n",
            "Epoch 1000/1000\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 1.1468 - mae: 0.8355 - val_loss: 1.2055 - val_mae: 0.8531\n",
            "Done!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5h86FEo80XhW",
        "colab_type": "text"
      },
      "source": [
        "## Convert the Tensorflow Model to Tensorflow Lite Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Egny1KLL0Wm0",
        "colab_type": "code",
        "outputId": "66241754-d251-45d6-e6c0-9032c79109d9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Convert the model to the TensorFlow Lite format with quantization\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "converter.optimizations = [tf.lite.Optimize.OPTIMIZE_FOR_SIZE]\n",
        "tflite_model = converter.convert()\n",
        "open(\"model.tflite\", \"wb\").write(tflite_model)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2532"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hFc5JmXo41H1",
        "colab_type": "text"
      },
      "source": [
        "## Predict"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ViQ7W8d-7PXK",
        "colab_type": "text"
      },
      "source": [
        "### Predict with Tensorflow Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AkGzRSdA478s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Use the model to make predictions from our test data\n",
        "\n",
        "############################################################\n",
        "#@markdown How to use the model to predict the result with the test data (`x_test`) and save the result in a variable `predictions`?\n",
        "script = \"predictions = model.predict(x_train)\" #@param {type:\"string\"}\n",
        "exec(script)\n",
        "############################################################"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KeH5sWiu7RhT",
        "colab_type": "text"
      },
      "source": [
        "### Predict with Tensorflow Lite Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ET8_k-vvwop0",
        "colab_type": "code",
        "cellView": "both",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 380
        },
        "outputId": "19153c48-4140-4ae7-e58c-d3b7eafc684f"
      },
      "source": [
        "# Use the Tensorflow lite model to make interfences from our test data\n",
        "#@markdown Please choose and fill in correct code statements from one of the following:\n",
        "#@markdown 1. interpreter.invoke() \n",
        "#@markdown 2. interpreter_input().fill(x_test[i])\n",
        "#@markdown 3. interpreter = tf.lite.Interpreter('model.tflite')\n",
        "#@markdown 4. interpreter_predictions[i] = interpreter_output()[0]\n",
        "#@markdown 5. interpreter_output = interpreter.tensor(interpreter.get_output_details()[0][\"index\"])\n",
        "#@markdown 6. interpreter_input = interpreter.tensor(interpreter.get_input_details()[0][\"index\"])\n",
        "\n",
        "############################################################\n",
        "# Instantiate an interpreter for the TFLite model\n",
        "#@markdown Which is the statement to instantiate an interpreter with a TFLite Model named `model.tflite`?\n",
        "script_1 = \"interpreter = tf.lite.Interpreter('model.tflite')\" #@param {type:\"string\"}\n",
        "exec(script_1)\n",
        "############################################################\n",
        "\n",
        "# Allocate memory for the model\n",
        "interpreter.allocate_tensors()\n",
        "\n",
        "############################################################\n",
        "# Get the input tensors so we can feed in values \n",
        "#@markdown Which is the statement to get input sensors?\n",
        "script_2 = \"interpreter_input = interpreter.tensor(interpreter.get_input_details()[0][\\\"index\\\"])\" #@param {type:\"string\"}\n",
        "exec(script_2)\n",
        "############################################################\n",
        "\n",
        "############################################################\n",
        "# Get the output tensors so we can get the results\n",
        "#@markdown Which is the statement to get output sensors?\n",
        "script_3 = \"interpreter.tensor(interpreter.get_output_details()[0][\\\"index\\\"])\" #@param {type:\"string\"}\n",
        "exec(script_3)\n",
        "############################################################\n",
        "\n",
        "# Create arrays to store the results\n",
        "interpreter_predictions = np.empty(x_test.size)\n",
        "\n",
        "# Run each model's interpreter for each value and store the results in arrays\n",
        "for i in range(x_test.size):\n",
        "  ############################################################\n",
        "  #@markdown Which is the statement to fill the input of the interpreter with `x_test[i]`?\n",
        "  script_4 = \"interpreter_input().fill(x_test[i])\" #@param {type:\"string\"}\n",
        "  exec(script_4)\n",
        "  ############################################################\n",
        "  ############################################################\n",
        "  #@markdown Which is the statement to invoke the interpreter?\n",
        "  script_5 = \"interpreter.invoke()\" #@param {type:\"string\"}\n",
        "  exec(script_5)\n",
        "  ############################################################\n",
        "  ############################################################\n",
        "  #@markdown Which is the statement to get the output from the interpreter and save the output in `interpreter_predictions[i]`?\n",
        "  script_6 = \"interpreter_predictions[i] = interpreter_output()[0]\"#@param {type:\"string\"}\n",
        "  exec(script_6)\n",
        "  ############################################################\n",
        "\n",
        "\n",
        "# Make the shape of the y_test be the same as the predictions\n",
        "y_test = np.reshape(y_test, predictions.shape)\n",
        "# Make the shape of the interpreter_predictions be the same as the predictions\n",
        "interpreter_predictions = np.reshape(interpreter_predictions, predictions.shape)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-c3dbf7cd2865>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mscript_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"interpreter = tf.lite.Interpreter('model.tflite')\"\u001b[0m \u001b[0;31m#@param {type:\"string\"}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mexec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscript_1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;31m############################################################\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Allocate memory for the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<string>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/lite/python/interpreter.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, model_path, model_content, experimental_delegates)\u001b[0m\n\u001b[1;32m    202\u001b[0m       self._interpreter = (\n\u001b[1;32m    203\u001b[0m           _interpreter_wrapper.InterpreterWrapper_CreateWrapperCPPFromFile(\n\u001b[0;32m--> 204\u001b[0;31m               model_path, self._custom_op_registerers))\n\u001b[0m\u001b[1;32m    205\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_interpreter\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Failed to open {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Could not open 'model.tflite'."
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ciEdnWpc1rR5",
        "colab_type": "text"
      },
      "source": [
        "## Plot the Result"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "svBsN_bVu1HL",
        "colab_type": "code",
        "outputId": "8736ad5c-9967-42e7-8644-b60d003b1ae1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 634
        }
      },
      "source": [
        "plt.clf()\n",
        "plt.title('Test data predicted vs actual values')\n",
        "plt.plot(x_test, y_test, 'b.', label='Actual')\n",
        "plt.plot(x_test, predictions, 'r.', label='Predicted (tensorflow)')\n",
        "############################################################\n",
        "#@markdown Please write the statement to plot the outputs in green dots with a label `Predicted (tflite)` from the interpreter.\n",
        "script = \"plt.plot(x_train, predictions, 'g.', label='Predicted')\"#@param {type:\"string\"}\n",
        "exec(script)\n",
        "############################################################\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-73c8ca84fb34>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Test data predicted vs actual values'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'b.'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Actual'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r.'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Predicted (tensorflow)'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;31m############################################################\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m#@markdown Please write the statement to plot the outputs in green dots with a label `Predicted (tflite)` from the interpreter.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2761\u001b[0m     return gca().plot(\n\u001b[1;32m   2762\u001b[0m         *args, scalex=scalex, scaley=scaley, **({\"data\": data} if data\n\u001b[0;32m-> 2763\u001b[0;31m         is not None else {}), **kwargs)\n\u001b[0m\u001b[1;32m   2764\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2765\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(self, scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1644\u001b[0m         \"\"\"\n\u001b[1;32m   1645\u001b[0m         \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcbook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize_kwargs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmlines\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLine2D\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1646\u001b[0;31m         \u001b[0mlines\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_lines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1647\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlines\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1648\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    214\u001b[0m                 \u001b[0mthis\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m                 \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m             \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_plot_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_next_color\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m_plot_args\u001b[0;34m(self, tup, kwargs)\u001b[0m\n\u001b[1;32m    340\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 342\u001b[0;31m             raise ValueError(f\"x and y must have same first dimension, but \"\n\u001b[0m\u001b[1;32m    343\u001b[0m                              f\"have shapes {x.shape} and {y.shape}\")\n\u001b[1;32m    344\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: x and y must have same first dimension, but have shapes (200,) and (600, 1)"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}